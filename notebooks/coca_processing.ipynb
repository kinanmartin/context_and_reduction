{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "coca_dir = \"../data/coca/text/text_spoken_kde/\"\n",
    "\n",
    "# dataset = load_dataset('text', data_dir=coca_dir)\n",
    "dataset = load_dataset('text', data_files=coca_dir+'w_spok_201*.txt')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##4072661 @!NANCY-GRACE-HOST : A 5-year-old Florida girl tucked into bed , five hours later , shes g\n"
     ]
    }
   ],
   "source": [
    "example_line = random.choice(train_dataset)\n",
    "print(example_line['text'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (text cleaning)\n",
    "\n",
    "Goal: From COCA's spoken genre, make a .txt file of new-line separated sentences. Clean formatting incl. speaker codes and weird tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_string_id=81\n",
      "len(example_string)=15290\n",
      "##4072612 @!ROBIN-ROBERTS-@1-A# @(Off-camera) Oh , come on upstairs here , Sam . Now , the dos and d\n"
     ]
    }
   ],
   "source": [
    "example_string_id = random.randint(0, len(train_dataset) - 1)\n",
    "example_string = train_dataset[example_string_id]['text']\n",
    "print(f'{example_string_id=}')\n",
    "print(f'{len(example_string)=}')\n",
    "print(example_string[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 [929, 972, 1084, 1047, 1018, 982, 1020, 929, 1053, 1054, 943, 1122, 1023, 1053, 767]\n",
      "##4072612 @!ROBIN-ROBERTS-@1-A# @(Off-camera) Oh ,\n",
      ". @!STEVE-HARVEY-@1-AB# @(Off-camera) Yeah . @!ROB\n",
      "couple . We have , let 's see , Robert is a 51-yea\n",
      "lets Christine know they 're having a wonderful da\n",
      "right there . Just meeting somebody . @GRAPHICS @G\n",
      "whole evening right there . @!ROBIN-ROBERTS-@1-A# \n",
      "audience are here all shaking , you , you like tha\n",
      "to know before you waste a lot of time , emotion ,\n",
      "that lady keep talking about anyway . @!ROBIN-ROBE\n",
      "@!DEE-DEE-@130'S-PUB# There are better products no\n",
      "right . @!ROBIN-ROBERTS-@1-A# @(Off-camera) It was\n",
      "noticed he was a little ... @!ROBIN-ROBERTS-@1-A# \n",
      ", you know , I do n't like your hair . What are yo\n",
      "you know , they are going out on a second date . O\n",
      "skating . @!GEORGE-STEPHANOPOU# @(Off-camera) Also\n"
     ]
    }
   ],
   "source": [
    "def separate_chunks(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    COCA is composed of scrambled chunks split by \"@\" * 10 (possibly \n",
    "    cut off at end of file). \n",
    "    Returns a list of separated chunks.\n",
    "    \"\"\"\n",
    "    return text.split(' @ @ @ @ @ @ @ @ @ @ ')\n",
    "\n",
    "\n",
    "example_chunks = separate_chunks(example_string)\n",
    "print(len(example_chunks), [len(chunk) for chunk in example_chunks])\n",
    "for chunk in example_chunks:\n",
    "    print(chunk[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_chunk_id=0\n",
      "##4072612 @!ROBIN-ROBERTS-@1-A# @(Off-camera) Oh , come on upstairs here , Sam . Now , the dos and don'ts of a first date . What can you do on a first date to make sure there is a second one ? A third one ? We found some brave souls who let us follow them on a blind date to find out what they 're doing right , and what they could be doing better . Joining us now with advice for our singles is \" GMA 's \" relationship guru , and the author of the best-selling relationship book , \" Act Like A Lady , Think Like A Man , \" Mr. Steve Harvey . And you always come with your own audience too here . @GRAPHICS @GRAPHICS @!STEVE-HARVEY-@1-AB# @(Off-camera) I bring a crowd with me . I always do better with people watching me . I do n't know what , a little showoff thing , maybe , I do n't know . @!ROBIN-ROBERTS-@1-A# @(Off-camera) There 's something , get on with that , but I 'm , I 'm going to let that go . @!STEVE-HARVEY-@1-AB#\n",
      "##4072612 .  .  Oh , come on upstairs here , Sam . Now , the dos and don'ts of a first date . What can you do on a first date to make sure there is a second one ? A third one ? We found some brave souls who let us follow them on a blind date to find out what they 're doing right , and what they could be doing better . Joining us now with advice for our singles is \" GMA 's \" relationship guru , and the author of the best-selling relationship book , \" Act Like A Lady , Think Like A Man , \" Mr. Steve Harvey . And you always come with your own audience too here . .  .  .  .  I bring a crowd with me . I always do better with people watching me . I do n't know what , a little showoff thing , maybe , I do n't know . .  .  There 's something , get on with that , but I 'm , I 'm going to let that go . . \n",
      "----\n",
      "0 ##4072612 \n",
      "1 Oh , come on upstairs here , Sam . Now , the dos and don'ts of a first date . What can you do on a first date to make sure there is a second one ? A third one ? We found some brave souls who let us follow them on a blind date to find out what they 're doing right , and what they could be doing better . Joining us now with advice for our singles is \" GMA 's \" relationship guru , and the author of the best-selling relationship book , \" Act Like A Lady , Think Like A Man , \" Mr. Steve Harvey . And you always come with your own audience too here . \n",
      "2 I bring a crowd with me . I always do better with people watching me . I do n't know what , a little showoff thing , maybe , I do n't know . \n",
      "3 There 's something , get on with that , but I 'm , I 'm going to let that go . @!STEVE-HARVEY-@1-AB#\n"
     ]
    }
   ],
   "source": [
    "def remove_speaker_and_other_tags(chunk: str, remove_nonspeaker_tags=True) -> str:\n",
    "    \"\"\"\n",
    "    DEPRECATED: it's better to split text by these tags instead of removing them\n",
    "    Remove from one chunk speaker tags (ex: @!BOB:) and optionally\n",
    "    other tags (ex: @(End-of-clip)).\n",
    "    \"\"\"\n",
    "    pattern = r\"\\s+@\\S+\" if remove_nonspeaker_tags else r\"\\s+@!\\S+\"\n",
    "    return re.sub(pattern, \" . \", chunk)\n",
    "\n",
    "def split_by_speaker_and_other_tags(\n",
    "        chunk: str, \n",
    "        remove_nonspeaker_tags=True,\n",
    "        ) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits one chunk by speaker tags (ex: @!BOB) and optionally\n",
    "        other tags (ex: @(End-of-clip)).\n",
    "\n",
    "    remove_nonspeaker_tags: also removes things like @(End-of-clip). \n",
    "        speaker tag: @!BOB  non-speaker tag @BOB (no \"!\")\n",
    "        Does not remove long portions inside of @(Clip-from-previous blocks\n",
    "    \n",
    "    Notes:\n",
    "        - Pattern makes first word in turn start with a space.\n",
    "        To remove it, add an \\s at the end of the pattern, but be aware\n",
    "        that this will break pattern matching of consecutive tags.\n",
    "        - Speaker tags are inconsistently either marked as \n",
    "            \"@!BOB\", \"@!BOB:\", \"@!BOB :\", \"@!BOB ( voiceover ) :\", \n",
    "            and more. ( voiceover ) is currently not captured.\n",
    "\n",
    "    \"\"\"\n",
    "    # pattern = r\"\\s+@\\S+\" if remove_nonspeaker_tags else r\"\\s+@!\\S+\"\n",
    "    pattern = r\"@\\S+(?:\\s:|)\\s\" if remove_nonspeaker_tags else r\"@!\\S+(?:\\s:|)\\s\"\n",
    "    out = re.split(pattern, chunk)\n",
    "    out = [segment for segment in out if segment.strip()]\n",
    "    return out\n",
    "\n",
    "\n",
    "example_chunk_id = random.randint(0, len(example_chunks)-1)\n",
    "print(f'{example_chunk_id=}')\n",
    "example_chunk = example_chunks[example_chunk_id]\n",
    "print(example_chunk)\n",
    "print(remove_speaker_and_other_tags(example_chunk))\n",
    "print('----')\n",
    "example_turns = split_by_speaker_and_other_tags(example_chunk)\n",
    "for turn_number, turn in enumerate(example_turns):\n",
    "    print(turn_number, turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oh , come on upstairs here , Sam .',\n",
       " \"Now , the dos and don'ts of a first date .\",\n",
       " 'What can you do on a first date to make sure there is a second one ?',\n",
       " 'A third one ?',\n",
       " \"We found some brave souls who let us follow them on a blind date to find out what they 're doing right , and what they could be doing better .\",\n",
       " 'Joining us now with advice for our singles is \" GMA \\'s \" relationship guru , and the author of the best-selling relationship book , \" Act Like A Lady , Think Like A Man , \" Mr. Steve Harvey .',\n",
       " 'And you always come with your own audience too here .']"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_turn_into_sentences(\n",
    "        turn: str, \n",
    "        # exclude_sentences_with_ellipses=False\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Splits one tag-free turn (as separated by split_by_speaker_and_other_tags) \n",
    "        into sentences.\n",
    "    Since COCA has space-separated punctuation, splits are done by:\n",
    "        [' . ', ' ? ', ' ! ']\n",
    "    \"\"\"\n",
    "    delimiters = [' . ', ' ? ', ' ! ']\n",
    "    pattern = \"|\".join(map(re.escape, delimiters))\n",
    "    pattern = '(' + pattern + ')' # retain delimiters\n",
    "    splits = re.split(pattern, turn)\n",
    "    if len(splits) == 1:\n",
    "        return splits\n",
    "    \n",
    "    # For multi-sentence utterances, we must manually re-combine punctuation\n",
    "    out = []\n",
    "    for idx, split in enumerate(splits):\n",
    "        if not split:\n",
    "            continue\n",
    "        if not (idx % 2): # is sentence\n",
    "            out.append(split)\n",
    "        else: # is delimiter\n",
    "            out[-1] += split[:-1] # don't include space after punctuation\n",
    "    return out\n",
    "    \n",
    "turn = example_turns[random.randint(0, len(example_turns)-1)]\n",
    "split_turn_into_sentences(turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_number=11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Right .',\n",
       " 'But you have to complete the cycle .',\n",
       " 'You know ?',\n",
       " 'Take her coat off .',\n",
       " 'Follow through .',\n",
       " 'Pull the chair out .',\n",
       " 'Scoot her up under the table .',\n",
       " \"That stuff 's not old-fashioned , man .\",\n",
       " 'That stuff is the game , you know ?',\n",
       " \"When he asked about , saying about you 're , you got an earthy look , that sat a little ... \",\n",
       " 'You know you got to , you know , like I said before .',\n",
       " \"You know , it 's a time to assess some information .\",\n",
       " 'Right .',\n",
       " 'What guy do you know uses the word earthy ?',\n",
       " 'You look earthy .',\n",
       " \"That 's dirt , you know .\",\n",
       " 'Now , this is an attractive woman .',\n",
       " 'She is. ',\n",
       " 'This is an attractive girl who has nice hair .',\n",
       " 'But he takes such a negative tone in this whole thing .',\n",
       " 'You know , I see you got that earthy look going .']"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_chunk_into_sentences(\n",
    "        chunk: str,\n",
    "        exclude_first_and_last_sentences=True,\n",
    "        remove_nonspeaker_tags=True,\n",
    "        ) -> List[str]:\n",
    "    \"\"\"\n",
    "    Combines `split_by_speaker_and_other_tags` and \n",
    "        `split_turn_into_sentences` to split a COCA chunk\n",
    "        into a list of sentences.\n",
    "\n",
    "    exclude_first_and_last_sentences: because the first and \n",
    "        last sentences are likely fragments split by the chunk border\n",
    "    \"\"\"\n",
    "    turns = split_by_speaker_and_other_tags(chunk, \n",
    "                                            remove_nonspeaker_tags)\n",
    "    sentences = []\n",
    "    for turn in turns:\n",
    "        sentences.extend(split_turn_into_sentences(turn))\n",
    "    return sentences[1:-1] if exclude_first_and_last_sentences else sentences\n",
    "\n",
    "chunk_number = random.randint(0, len(example_chunks)-1)\n",
    "example_chunk = example_chunks[chunk_number]\n",
    "example_sentences = split_chunk_into_sentences(example_chunk, \n",
    "                                               exclude_first_and_last_sentences=True)\n",
    "print(f'{chunk_number=}')\n",
    "example_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noticed he was a little ... @!ROBIN-ROBERTS-@1-A# @(Off-camera) Right . @!STEVE-HARVEY-@1-AB# @(Off-camera) But you have to complete the cycle . You know ? Take her coat off . @!ROBIN-ROBERTS-@1-A# @(Off-camera) Follow through . @!STEVE-HARVEY-@1-AB# @(Off-camera) Pull the chair out . Scoot her up under the table . That stuff 's not old-fashioned , man . That stuff is the game , you know ? @!ROBIN-ROBERTS-@1-A# @(Off-camera) When he asked about , saying about you 're , you got an earthy look , that sat a little ... @!STEVE-HARVEY-@1-AB# @(Off-camera) You know you got to , you know , like I said before . You know , it 's a time to assess some information . @!ROBIN-ROBERTS-@1-A# @(Off-camera) Right . @!STEVE-HARVEY-@1-AB# @(Off-camera) What guy do you know uses the word earthy ? You look earthy . That 's dirt , you know . Now , this is an attractive woman . @!ROBIN-ROBERTS-@1-A# @(Off-camera) She is. @!STEVE-HARVEY-@1-AB# @(Off-camera) This is an attractive girl who has nice hair . But he takes such a negative tone in this whole thing . You know , I see you got that earthy look going . @!ROBIN-ROBERTS-@1-A#\n"
     ]
    }
   ],
   "source": [
    "print(example_chunks[chunk_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:00<00:00, 7954.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_coca_file(\n",
    "        input_file_path: Path,\n",
    "        output_dir_path: Path,\n",
    "        overwrite=True,\n",
    "        exclude_first_and_last_sentences=True,\n",
    "        remove_nonspeaker_tags=True,\n",
    "        ) -> None:\n",
    "    assert input_file_path.exists(), f'File \"{input_file_path}\" not found'\n",
    "    dataset_dict = load_dataset('text', data_files=str(input_file_path))\n",
    "    dataset = dataset_dict['train']\n",
    "\n",
    "    output_dir_path.mkdir(parents=True, exist_ok=overwrite)\n",
    "    output_file_path = output_dir_path / (input_file_path.stem + '_cleaned.txt')\n",
    "\n",
    "    f = open(output_file_path, 'w')\n",
    "    for line in tqdm(dataset):\n",
    "        text = line['text']\n",
    "        chunks = separate_chunks(text)\n",
    "        for chunk in chunks:\n",
    "            sentences = split_chunk_into_sentences(chunk,\n",
    "                                                   exclude_first_and_last_sentences,\n",
    "                                                   remove_nonspeaker_tags)\n",
    "            f.write('\\n'.join(sentences) + '\\n')\n",
    "\n",
    "    f.close()\n",
    "    return None\n",
    "        \n",
    "clean_coca_file(\n",
    "    input_file_path=Path(\"../data/coca/text/text_spoken_kde/w_spok_2000.txt\"),\n",
    "    output_dir_path=Path(\"../data/coca_spoken/text_cleaned/\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
