{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "coca_dir = \"../data/coca/text/text_spoken_kde/\"\n",
    "\n",
    "# dataset = load_dataset('text', data_dir=coca_dir)\n",
    "dataset = load_dataset('text', data_files=coca_dir+'w_spok_201*.txt')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##4072661 @!NANCY-GRACE-HOST : A 5-year-old Florida girl tucked into bed , five hours later , shes g\n"
     ]
    }
   ],
   "source": [
    "example_line = random.choice(train_dataset)\n",
    "print(example_line['text'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (text cleaning)\n",
    "\n",
    "Goal: From COCA's spoken genre, make a .txt file of new-line separated sentences. Clean formatting incl. speaker codes and weird tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_string_id=81\n",
      "len(example_string)=15290\n",
      "##4072612 @!ROBIN-ROBERTS-@1-A# @(Off-camera) Oh , come on upstairs here , Sam . Now , the dos and d\n"
     ]
    }
   ],
   "source": [
    "example_string_id = random.randint(0, len(train_dataset) - 1)\n",
    "example_string = train_dataset[example_string_id]['text']\n",
    "print(f'{example_string_id=}')\n",
    "print(f'{len(example_string)=}')\n",
    "print(example_string[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 [929, 972, 1084, 1047, 1018, 982, 1020, 929, 1053, 1054, 943, 1122, 1023, 1053, 767]\n",
      "##4072612 @!ROBIN-ROBERTS-@1-A# @(Off-camera) Oh ,\n",
      ". @!STEVE-HARVEY-@1-AB# @(Off-camera) Yeah . @!ROB\n",
      "couple . We have , let 's see , Robert is a 51-yea\n",
      "lets Christine know they 're having a wonderful da\n",
      "right there . Just meeting somebody . @GRAPHICS @G\n",
      "whole evening right there . @!ROBIN-ROBERTS-@1-A# \n",
      "audience are here all shaking , you , you like tha\n",
      "to know before you waste a lot of time , emotion ,\n",
      "that lady keep talking about anyway . @!ROBIN-ROBE\n",
      "@!DEE-DEE-@130'S-PUB# There are better products no\n",
      "right . @!ROBIN-ROBERTS-@1-A# @(Off-camera) It was\n",
      "noticed he was a little ... @!ROBIN-ROBERTS-@1-A# \n",
      ", you know , I do n't like your hair . What are yo\n",
      "you know , they are going out on a second date . O\n",
      "skating . @!GEORGE-STEPHANOPOU# @(Off-camera) Also\n"
     ]
    }
   ],
   "source": [
    "def separate_chunks(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    COCA is composed of scrambled chunks split by \"@\" * 10 (possibly \n",
    "    cut off at end of file). \n",
    "    Returns a list of separated chunks.\n",
    "    \"\"\"\n",
    "    return text.split(' @ @ @ @ @ @ @ @ @ @ ')\n",
    "\n",
    "\n",
    "example_chunks = separate_chunks(example_string)\n",
    "print(len(example_chunks), [len(chunk) for chunk in example_chunks])\n",
    "for chunk in example_chunks:\n",
    "    print(chunk[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_chunk_id=8\n",
      "that lady keep talking about anyway . @!ROBIN-ROBERTS-@1-A# @(Off-camera) Denise , is that you , Denise ? Get out of , get out of Steve 's ear . All right . Our next couple , our next couple , Dane Potter . Dane is a 35-year-old actor . Dee Dee is in her 30 's and works in public relations . This is their first date . @GRAPHICS @!ROBIN-ROBERTS-@1-A# @(Voiceover) Dane starts things off with flowers for Dee Dee . @!DANE-@135-YEAR-OLD# I 'm Dane . @!DEE-DEE-@130'S-PUB# I 'm Dee Dee . @!DANE-@135-YEAR-OLD# Nice to meet you . @!DEE-DEE-@130'S-PUB# You too . @!DANE-@135-YEAR-OLD# These are for you . @!DEE-DEE-@130'S-PUB# Thank you , these are beautiful . @GRAPHICS @!ROBIN-ROBERTS-@1-A# @(Voiceover) At the table , Dane does not pull out Dee Dee 's chair or take her coat . When Dane asks about Dee Dee 's look , how much is too much ? @!DANE-@135-YEAR-OLD# You got the earthy look going . @!DEE-DEE-@130'S-PUB# It did n't have anything to do with like being earthy . It really was like I had a really bad relaxer a few years ago , have n't seen their\n",
      "that lady keep talking about anyway . .  .  Denise , is that you , Denise ? Get out of , get out of Steve 's ear . All right . Our next couple , our next couple , Dane Potter . Dane is a 35-year-old actor . Dee Dee is in her 30 's and works in public relations . This is their first date . .  .  .  Dane starts things off with flowers for Dee Dee . .  I 'm Dane . .  I 'm Dee Dee . .  Nice to meet you . .  You too . .  These are for you . .  Thank you , these are beautiful . .  .  .  At the table , Dane does not pull out Dee Dee 's chair or take her coat . When Dane asks about Dee Dee 's look , how much is too much ? .  You got the earthy look going . .  It did n't have anything to do with like being earthy . It really was like I had a really bad relaxer a few years ago , have n't seen their\n",
      "----\n",
      "0 that lady keep talking about anyway .\n",
      "1  Denise , is that you , Denise ? Get out of , get out of Steve 's ear . All right . Our next couple , our next couple , Dane Potter . Dane is a 35-year-old actor . Dee Dee is in her 30 's and works in public relations . This is their first date .\n",
      "2  Dane starts things off with flowers for Dee Dee .\n",
      "3  I 'm Dane .\n",
      "4  I 'm Dee Dee .\n",
      "5  Nice to meet you .\n",
      "6  You too .\n",
      "7  These are for you .\n",
      "8  Thank you , these are beautiful .\n",
      "9  At the table , Dane does not pull out Dee Dee 's chair or take her coat . When Dane asks about Dee Dee 's look , how much is too much ?\n",
      "10  You got the earthy look going .\n",
      "11  It did n't have anything to do with like being earthy . It really was like I had a really bad relaxer a few years ago , have n't seen their\n"
     ]
    }
   ],
   "source": [
    "def remove_speaker_and_other_tags(chunk: str, remove_other_tags=True) -> str:\n",
    "    \"\"\"\n",
    "    Remove from one chunk speaker tags (ex: @!BOB:) and optionally\n",
    "    other tags (ex: @(End-of-clip)).\n",
    "    \"\"\"\n",
    "    pattern = r\"\\s+@\\S+\" if remove_other_tags else r\"\\s+@!\\S+\"\n",
    "    return re.sub(pattern, \" . \", chunk)\n",
    "\n",
    "def split_by_speaker_and_other_tags(\n",
    "        chunk: str, \n",
    "        remove_other_tags=True,\n",
    "        ) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits one chunk by speaker tags (ex: @!BOB) and optionally\n",
    "        other tags (ex: @(End-of-clip)).\n",
    "\n",
    "    remove_other_tags: also removes things like \n",
    "        @(End-of-clip).\n",
    "        Does not remove long portions inside of @(Clip-from-previous blocks\n",
    "    \n",
    "    Notes:\n",
    "        - Pattern makes first word in turn start with a space.\n",
    "        To remove it, add an \\s at the end of the pattern, but be aware\n",
    "        that this will break pattern matching of consecutive tags.\n",
    "        - Speaker tags are inconsistently either marked as \n",
    "            \"@!BOB\", \"@!BOB:\", \"@!BOB :\", \"@!BOB ( voiceover ) :\", \n",
    "            and more. ( voiceover ) is currently not captured.\n",
    "\n",
    "    \"\"\"\n",
    "    pattern = r\"\\s+@\\S+\" if remove_other_tags else r\"\\s+@!\\S+\"\n",
    "    # pattern = r\"\\s+@!\\S+(?:\\s*\\(.*\\))?(?::|\\s:)\"\n",
    "    # pattern = r'(@\\S+(?:\\s*\\(\\s*voiceover\\s*\\)\\s*)?[: ]?)'\n",
    "    # pattern = r\"\\s+@!\\S+(?: :|\\s:)\" if remove_other_tags else r\"\\s+@!\\S+(:|\\s)\"\n",
    "    out = re.split(pattern, chunk)\n",
    "    out = [segment for segment in out if segment.strip()]\n",
    "    return out\n",
    "\n",
    "example_chunk_id = random.randint(0, len(example_chunks)-1)\n",
    "print(f'{example_chunk_id=}')\n",
    "example_chunk = example_chunks[example_chunk_id]\n",
    "print(example_chunk)\n",
    "print(remove_speaker_and_other_tags(example_chunk))\n",
    "print('----')\n",
    "example_turns = split_by_speaker_and_other_tags(example_chunk)\n",
    "for turn_number, turn in enumerate(example_turns):\n",
    "    print(turn_number, turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Denise , is that you , Denise ?',\n",
       " \" Get out of , get out of Steve 's ear .\",\n",
       " ' All right .',\n",
       " ' Our next couple , our next couple , Dane Potter .',\n",
       " ' Dane is a 35-year-old actor .',\n",
       " \" Dee Dee is in her 30 's and works in public relations .\",\n",
       " ' This is their first date .']"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_turn_into_sentences(\n",
    "        turn: str, \n",
    "        # exclude_sentences_with_ellipses=False\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Splits one tag-free turn (as separated by split_by_speaker_and_other_tags) \n",
    "        into sentences.\n",
    "    Since COCA has space-separated punctuation, splits are done by:\n",
    "        [' . ', ' ? ', ' ! ']\n",
    "    \"\"\"\n",
    "    delimiters = [' . ', ' ? ', ' ! ']\n",
    "    pattern = \"|\".join(map(re.escape, delimiters))\n",
    "    pattern = '(' + pattern + ')'\n",
    "    splits = re.split(pattern, turn)\n",
    "    if len(splits) == 1:\n",
    "        return splits\n",
    "    \n",
    "    # Else, manually re-insert punctuation\n",
    "    out = []\n",
    "    for idx, split in enumerate(splits):\n",
    "        if not (idx % 2): # is sentence\n",
    "            if idx == 0:\n",
    "                out.append(split)\n",
    "            else: # add prefix space for consistency\n",
    "                out.append(' ' + split)\n",
    "        else: # is delimiter\n",
    "            out[-1] += split[:-1]\n",
    "    return out\n",
    "    \n",
    "turn = example_turns[random.randint(0, len(example_turns)-1)]\n",
    "split_turn_into_sentences(turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_number=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" Also , we 're going to take a look inside Oprah 's closet .\",\n",
       " ' She is giving everyone a chance to have a piece of her wardrobe .',\n",
       " \" She 's going to auction it off for charity .\",\n",
       " ' And you can , you can bid on it .',\n",
       " \" Also , we 're going to get some tips on how to declutter your own closet .\",\n",
       " \" You can now walk in Oprah 's shoes .\",\n",
       " \" I do n't want to walk in Oprah 's shoes , but I 'm sure a lot of people out there do .\",\n",
       " \" And we 're going to get to Kathryn Bigelow today .\",\n",
       " ' We promise we will do that today .',\n",
       " ' We are going to have the story on Kathryn Bigelow .',\n",
       " ' Last half hour .']"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_chunk_into_sentences(\n",
    "        chunk: str,\n",
    "        exclude_first_and_last_sentences=True,\n",
    "        ) -> List[str]:\n",
    "    \"\"\"\n",
    "    Combines `split_by_speaker_and_other_tags` and \n",
    "        `split_turn_into_sentences` to split a COCA chunk\n",
    "        into a list of sentences.\n",
    "\n",
    "    exclude_first_and_last_sentences: because the first and \n",
    "        last sentences are likely fragments split by the chunk border\n",
    "    \"\"\"\n",
    "    turns = split_by_speaker_and_other_tags(chunk)\n",
    "    sentences = []\n",
    "    for turn in turns:\n",
    "        sentences.extend(split_turn_into_sentences(turn))\n",
    "    return sentences[1:-1] if exclude_first_and_last_sentences else sentences\n",
    "\n",
    "chunk_number = random.randint(0, len(example_chunks)-1)\n",
    "example_chunk = example_chunks[chunk_number]\n",
    "example_sentences = split_chunk_into_sentences(example_chunk, \n",
    "                                               exclude_first_and_last_sentences=True)\n",
    "print(f'{chunk_number=}')\n",
    "example_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skating . @!GEORGE-STEPHANOPOU# @(Off-camera) Also , we 're going to take a look inside Oprah 's closet . She is giving everyone a chance to have a piece of her wardrobe . She 's going to auction it off for charity . And you can , you can bid on it . @!GEORGE-STEPHANOPOU# @(Voiceover) Also , we 're going to get some tips on how to declutter your own closet . You can now walk in Oprah 's shoes . I do n't want to walk in Oprah 's shoes , but I 'm sure a lot of people out there do . @!ROBIN-ROBERTS-@1-A# @(Off-camera) And we 're going to get to Kathryn Bigelow today . @!GEORGE-STEPHANOPOU# @(Off-camera) We promise we will do that today . @!ROBIN-ROBERTS-@1-A# @(Off-camera) We are going to have the story on Kathryn Bigelow . Last half hour . COMMERCIAL BREAK ' \n"
     ]
    }
   ],
   "source": [
    "print(example_chunks[chunk_number])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
