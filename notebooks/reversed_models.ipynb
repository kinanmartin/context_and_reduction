{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from transformers import BertTokenizer, BertForMaskedLM, GPT2Tokenizer, GPT2Config, GPT2Model, GPT2LMHeadModel, GPT2LMHeadModel\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading normal tokenized dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data_path = '../data/coca_spoken/tokens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_datasets = load_from_disk(tokenized_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4802969\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 600371\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 600372\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'He sees things very similar .',\n",
       " 'input_ids': [1544, 7224, 1243, 845, 2092, 764],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = encoded_datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'He sees things very similar .', 'input_ids': [1544, 7224, 1243, 845, 2092, 764], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'He ran a very strong race in New Hampshire .', 'input_ids': [1544, 4966, 257, 845, 1913, 3234, 287, 968, 13910, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'So what is the significance of all this Mark ?', 'input_ids': [2396, 644, 318, 262, 12085, 286, 477, 428, 2940, 5633], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'And for those who have placed their faith in Jesus Christ , and can claim God as their father , then heaven is going to be their eternal life .', 'input_ids': [1870, 329, 883, 508, 423, 4624, 511, 4562, 287, 5803, 1951, 837, 290, 460, 1624, 1793, 355, 511, 2988, 837, 788, 9538, 318, 1016, 284, 307, 511, 15851, 1204, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'That is all we have time for today .', 'input_ids': [2504, 318, 477, 356, 423, 640, 329, 1909, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(encoded_datasets['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 10])\n",
      "tensor([[ 1544,  7224,  1243,   845,  2092,   764, 50256, 50256, 50256, 50256],\n",
      "        [ 1544,  4966,   257,   845,  1913,  3234,   287,   968, 13910,   764],\n",
      "        [ 2396,   644,   318,   262, 12085,   286,   477,   428,  2940,  5633]])\n",
      "attention_mask shape: torch.Size([3, 10])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "labels shape: torch.Size([3, 10])\n",
      "tensor([[ 1544,  7224,  1243,   845,  2092,   764,  -100,  -100,  -100,  -100],\n",
      "        [ 1544,  4966,   257,   845,  1913,  3234,   287,   968, 13910,   764],\n",
      "        [ 2396,   644,   318,   262, 12085,   286,   477,   428,  2940,  5633]])\n"
     ]
    }
   ],
   "source": [
    "example_data_collation = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "for key in example_data_collation:\n",
    "    print(f\"{key} shape: {example_data_collation[key].shape}\")\n",
    "    print(example_data_collation[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseSequenceDataCollator(DataCollatorForLanguageModeling):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        for feature in features:\n",
    "            feature['input_ids'] = feature['input_ids'][::-1]\n",
    "        return super().__call__(features, return_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_data_collator = ReverseSequenceDataCollator(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 10])\n",
      "tensor([[  764,  2092,   845,  1243,  7224,  1544, 50256, 50256, 50256, 50256],\n",
      "        [  764, 13910,   968,   287,  3234,  1913,   845,   257,  4966,  1544],\n",
      "        [ 5633,  2940,   428,   477,   286, 12085,   262,   318,   644,  2396]])\n",
      "attention_mask shape: torch.Size([3, 10])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "labels shape: torch.Size([3, 10])\n",
      "tensor([[  764,  2092,   845,  1243,  7224,  1544,  -100,  -100,  -100,  -100],\n",
      "        [  764, 13910,   968,   287,  3234,  1913,   845,   257,  4966,  1544],\n",
      "        [ 5633,  2940,   428,   477,   286, 12085,   262,   318,   644,  2396]])\n"
     ]
    }
   ],
   "source": [
    "example_data_collation = reverse_data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "for key in example_data_collation:\n",
    "    print(f\"{key} shape: {example_data_collation[key].shape}\")\n",
    "    print(example_data_collation[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokens are correctly reversed, but padding is put at the end of the input. This should be still fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated method below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with reversing the tokens of the dataset (as below) is that the data is by default not loaded into memory.\n",
    "\n",
    "I also would rather not make a clone of the dataset in reverse, since it would double the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokens(tokenized_dataset):\n",
    "    \"\"\"Reverses tokens INPLACE\"\"\"\n",
    "    for split in tokenized_dataset:\n",
    "        for i in tqdm(range(len(tokenized_dataset[split]))):\n",
    "            tokenized_dataset[split][i]['input_ids'].reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc95f4d584b4c45887f76a1b0e3a9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4802969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd110ca3249944dd9fad22ae18978793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9348347d8745848872f985b7be4b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reversed_encoded_datasets = load_from_disk(tokenized_data_path)\n",
    "reverse_tokens(reversed_encoded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'He sees things very similar .',\n",
       " 'input_ids': [1544, 7224, 1243, 845, 2092, 764],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_encoded_datasets['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
