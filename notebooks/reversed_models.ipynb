{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from transformers import BertTokenizer, BertForMaskedLM, GPT2Tokenizer, GPT2Config, GPT2Model, GPT2LMHeadModel, GPT2LMHeadModel\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading normal tokenized dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data_path = '../data/coca_spoken/tokens_sentence/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_datasets = load_from_disk(tokenized_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4802969\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 600371\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 600372\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'He sees things very similar .',\n",
       " 'input_ids': [1544, 7224, 1243, 845, 2092, 764],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = encoded_datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'He sees things very similar .', 'input_ids': [1544, 7224, 1243, 845, 2092, 764], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'He ran a very strong race in New Hampshire .', 'input_ids': [1544, 4966, 257, 845, 1913, 3234, 287, 968, 13910, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'So what is the significance of all this Mark ?', 'input_ids': [2396, 644, 318, 262, 12085, 286, 477, 428, 2940, 5633], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'And for those who have placed their faith in Jesus Christ , and can claim God as their father , then heaven is going to be their eternal life .', 'input_ids': [1870, 329, 883, 508, 423, 4624, 511, 4562, 287, 5803, 1951, 837, 290, 460, 1624, 1793, 355, 511, 2988, 837, 788, 9538, 318, 1016, 284, 307, 511, 15851, 1204, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'text': 'That is all we have time for today .', 'input_ids': [2504, 318, 477, 356, 423, 640, 329, 1909, 764], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(encoded_datasets['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 10])\n",
      "tensor([[ 1544,  7224,  1243,   845,  2092,   764, 50256, 50256, 50256, 50256],\n",
      "        [ 1544,  4966,   257,   845,  1913,  3234,   287,   968, 13910,   764],\n",
      "        [ 2396,   644,   318,   262, 12085,   286,   477,   428,  2940,  5633]])\n",
      "attention_mask shape: torch.Size([3, 10])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "labels shape: torch.Size([3, 10])\n",
      "tensor([[ 1544,  7224,  1243,   845,  2092,   764,  -100,  -100,  -100,  -100],\n",
      "        [ 1544,  4966,   257,   845,  1913,  3234,   287,   968, 13910,   764],\n",
      "        [ 2396,   644,   318,   262, 12085,   286,   477,   428,  2940,  5633]])\n"
     ]
    }
   ],
   "source": [
    "example_data_collation = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "for key in example_data_collation:\n",
    "    print(f\"{key} shape: {example_data_collation[key].shape}\")\n",
    "    print(example_data_collation[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseSequenceDataCollator(DataCollatorForLanguageModeling):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        for feature in features:\n",
    "            feature['input_ids'] = feature['input_ids'][::-1]\n",
    "        return super().__call__(features, return_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_data_collator = ReverseSequenceDataCollator(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 10])\n",
      "tensor([[  764,  2092,   845,  1243,  7224,  1544, 50256, 50256, 50256, 50256],\n",
      "        [  764, 13910,   968,   287,  3234,  1913,   845,   257,  4966,  1544],\n",
      "        [ 5633,  2940,   428,   477,   286, 12085,   262,   318,   644,  2396]])\n",
      "attention_mask shape: torch.Size([3, 10])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "labels shape: torch.Size([3, 10])\n",
      "tensor([[  764,  2092,   845,  1243,  7224,  1544,  -100,  -100,  -100,  -100],\n",
      "        [  764, 13910,   968,   287,  3234,  1913,   845,   257,  4966,  1544],\n",
      "        [ 5633,  2940,   428,   477,   286, 12085,   262,   318,   644,  2396]])\n"
     ]
    }
   ],
   "source": [
    "example_data_collation = reverse_data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "for key in example_data_collation:\n",
    "    print(f\"{key} shape: {example_data_collation[key].shape}\")\n",
    "    print(example_data_collation[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokens are correctly reversed, but padding is put at the end of the input. This should be still fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional Data Collator(?)\n",
    "Can I simply modify the data collator like above to create the necessary input_ids, labels, and attention_mask for the Bidirectional model without having to modify anything internal to the GPT2LMHeadModel instance or Trainer training loop? let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalInfillingDataCollator(DataCollatorForLanguageModeling):\n",
    "    \"\"\"\n",
    "    Modifies the DataCollatorForLanguageModeling to return\n",
    "    input_ids, labels, and attention_ids\n",
    "    as per pqian11/fragment-completion code (Qian and Levy, 2022)\n",
    "    suitable for bidirectional infilling task\n",
    "\n",
    "    From a single input (token) sentence, I should be able to create a whole batch\n",
    "    of bidirectional task inputs where each successive token is masked.\n",
    "    \"\"\"\n",
    "    def __call__(self, features, return_tensors='pt', \n",
    "                 BLANK_id=-2000, SEP_id=-1000, FILLER_id=-3000):\n",
    "        \"\"\"\n",
    "        Given:\n",
    "            features := Dict{\n",
    "                'input_ids': List, \n",
    "                'attention_mask': List\n",
    "            }\n",
    "        Returns:\n",
    "            batch := transformers.tokenization_utils_base.BatchEncoding{\n",
    "                'input_ids': Tensor,\n",
    "                'attention_mask': Tensor,\n",
    "                'labels': Tensor\n",
    "            }\n",
    "\n",
    "        Example:\n",
    "            Given:\n",
    "                input_ids = [1544, 7224, 1243, 845, 2092, 764]\n",
    "                attention_mask = [1, 1, 1, 1, 1, 1]\n",
    "\n",
    "            Return:\n",
    "                bidi_input_ids = [1544, BLANK, 1243, 845, 2092, 764, SEP, FILL]\n",
    "                bidi_attention_mask = [1, 1, 1, 1, 1, 1, 1, 1]\n",
    "                bidi_labels = [BLANK, BLANK, BLANK, BLANK, BLANK, BLANK, BLANK, 7224]\n",
    "\n",
    "            * Ensure automatic shifting of labels doesn't happen in the model\n",
    "\n",
    "            (Note: Padding not necessary if we make the batch from the single sentence\n",
    "            Otherwise, we need to additionally pad all inputs with zeros at the end)\n",
    "\n",
    "        \"\"\"\n",
    "        # print(features)\n",
    "        # features := {'input_ids': List, 'attention_mask': List}\n",
    "        # for feature in features:\n",
    "        #     for key, val in feature.items():\n",
    "        #         # print(f\"{key} shape: {len(val)}\")\n",
    "        #         print(key, val)\n",
    "\n",
    "        # print(features)\n",
    "        \n",
    "        \n",
    "        # batch = {}\n",
    "        # for feature in features:\n",
    "        # feature = features[0]\n",
    "        assert isinstance(features, dict), f\"bidirectional data collator input features should be a dict, not {type(features)}\"\n",
    "        assert return_tensors == 'pt', f\"only supports return pytorch tensors\"\n",
    "\n",
    "        feature = features\n",
    "        input_ids = feature['input_ids']\n",
    "        # attention_mask = features['attention_mask']\n",
    "\n",
    "        n_tokens = len(input_ids)\n",
    "\n",
    "        bidi_input_ids = [input_ids[:i] + [BLANK_id] + input_ids[i+1:] + [SEP_id, FILLER_id] \n",
    "                        for i in range(n_tokens)]\n",
    "\n",
    "        bidi_attention_mask = [[1 for _ in range(n_tokens + 2)] for _ in range(n_tokens)]\n",
    "\n",
    "        bidi_labels = [[-100 for _ in range(n_tokens + 1)] + [answer_token] \n",
    "                    for answer_token in input_ids]\n",
    "\n",
    "        batch = {\n",
    "            'input_ids': torch.tensor(bidi_input_ids),\n",
    "            'attention_mask': torch.tensor(bidi_attention_mask),\n",
    "            'labels': torch.tensor(bidi_labels)\n",
    "        }\n",
    "        # print(batch)\n",
    "        return batch\n",
    "        # return super().__call__(features, return_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_data_collator = BidirectionalInfillingDataCollator(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_bidi_data_collation = bidirectional_data_collator(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[-2000,  7224,  1243,   845,  2092,   764, -1000, -3000],\n",
       "         [ 1544, -2000,  1243,   845,  2092,   764, -1000, -3000],\n",
       "         [ 1544,  7224, -2000,   845,  2092,   764, -1000, -3000],\n",
       "         [ 1544,  7224,  1243, -2000,  2092,   764, -1000, -3000],\n",
       "         [ 1544,  7224,  1243,   845, -2000,   764, -1000, -3000],\n",
       "         [ 1544,  7224,  1243,   845,  2092, -2000, -1000, -3000]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[-100, -100, -100, -100, -100, -100, -100, 1544],\n",
       "         [-100, -100, -100, -100, -100, -100, -100, 7224],\n",
       "         [-100, -100, -100, -100, -100, -100, -100, 1243],\n",
       "         [-100, -100, -100, -100, -100, -100, -100,  845],\n",
       "         [-100, -100, -100, -100, -100, -100, -100, 2092],\n",
       "         [-100, -100, -100, -100, -100, -100, -100,  764]])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_bidi_data_collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example_bidi_data_collation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_dir = '../models/bidi/test1/'\n",
    "args = TrainingArguments(\n",
    "    training_output_dir,\n",
    "    per_device_train_batch_size=128, # change to fit GPU specs\n",
    "    per_device_eval_batch_size=128,\n",
    "    group_by_length=True, # bucketing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = GPT2Config()\n",
    "model = GPT2LMHeadModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    # resume_from_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated method below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with reversing the tokens of the dataset (as below) is that the data is by default not loaded into memory.\n",
    "\n",
    "I also would rather not make a clone of the dataset in reverse, since it would double the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokens(tokenized_dataset):\n",
    "    \"\"\"Reverses tokens INPLACE\"\"\"\n",
    "    for split in tokenized_dataset:\n",
    "        for i in tqdm(range(len(tokenized_dataset[split]))):\n",
    "            tokenized_dataset[split][i]['input_ids'].reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc95f4d584b4c45887f76a1b0e3a9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4802969 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd110ca3249944dd9fad22ae18978793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9348347d8745848872f985b7be4b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reversed_encoded_datasets = load_from_disk(tokenized_data_path)\n",
    "reverse_tokens(reversed_encoded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'He sees things very similar .',\n",
       " 'input_ids': [1544, 7224, 1243, 845, 2092, 764],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_encoded_datasets['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
