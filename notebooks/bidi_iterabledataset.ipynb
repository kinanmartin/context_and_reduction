{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2TokenizerFast, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = \"models/script1/left_sentence/checkpoint-75047\"\n",
    "# # model_dir = \"gpt2\"\n",
    "# tokenizer_name = \"gpt2\"\n",
    "\n",
    "# model = load_pretrained_model(model_dir)\n",
    "# tokenizer = load_pretrained_tokenizer(tokenizer_name)\n",
    "# data_collator = init_data_collator(tokenizer, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_testset_dir = \"../data/coca_spoken/tokens_sentence/test\"\n",
    "test_set = load_from_disk(tokenized_testset_dir)\n",
    "# test_set = test_set.remove_columns('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 600372\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_tokenizer(pretrained_model_name_or_path, context=None, add_prefix_space=False):\n",
    "    print(f'Loading pretrained tokenizer from {pretrained_model_name_or_path}...')\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(\n",
    "        pretrained_model_name_or_path, \n",
    "        add_prefix_space=add_prefix_space, #?\n",
    "    )\n",
    "\n",
    "    if context == 'bigram':\n",
    "        tokenizer.bos_token = '<s>'\n",
    "        tokenizer.eos_token = '</s>'\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token # ?\n",
    "    print(\"Vocabulary size:\", tokenizer.vocab_size)\n",
    "    print(\"Max Model Input Sizes:\", tokenizer.model_max_length)\n",
    "    print(\"BOS token:\", tokenizer.bos_token, tokenizer.bos_token_id)\n",
    "    print(\"EOS token:\", tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "    print(\"PAD token:\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "    print(\"SEP token:\", tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "    print(\"UNK token:\", tokenizer.unk_token, tokenizer.unk_token_id)\n",
    "    print(\"Special tokens:\", tokenizer.all_special_tokens)\n",
    "    print('...done')\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK = '[BLANK]'\n",
    "FILLER = '[FILLER]'\n",
    "SEP = '[SEP]'\n",
    "BOS = '<s>'\n",
    "EOS = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained tokenizer from gpt2...\n",
      "Vocabulary size: 50257\n",
      "Max Model Input Sizes: 1024\n",
      "BOS token: <|endoftext|> 50256\n",
      "EOS token: <|endoftext|> 50256\n",
      "PAD token: <|endoftext|> 50256\n",
      "SEP token: None None\n",
      "UNK token: <|endoftext|> 50256\n",
      "Special tokens: ['<|endoftext|>']\n",
      "...done\n",
      "50257 50258 50259 50260 50261\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_pretrained_tokenizer('gpt2')\n",
    "num_added_tokens = tokenizer.add_tokens([BLANK, FILLER, SEP, BOS, EOS])\n",
    "\n",
    "BLANK_id = tokenizer.convert_tokens_to_ids(BLANK)\n",
    "FILLER_id = tokenizer.convert_tokens_to_ids(FILLER)\n",
    "SEP_id = tokenizer.convert_tokens_to_ids(SEP)\n",
    "BOS_id = tokenizer.convert_tokens_to_ids(BOS)\n",
    "EOS_id = tokenizer.convert_tokens_to_ids(EOS)\n",
    "print(BLANK_id, FILLER_id, SEP_id, BOS_id, EOS_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_inputs(example):\n",
    "\n",
    "    input_ids = example['input_ids']\n",
    "    # attention_mask = features['attention_mask']\n",
    "\n",
    "    n_tokens = len(input_ids)\n",
    "    \n",
    "    for i in range(n_tokens):\n",
    "        bidi_input_ids = [BOS_id] +  input_ids[:i] + [BLANK_id] + input_ids[i+1:] + [EOS_id] + [SEP_id, FILLER_id]\n",
    "        bidi_attention_mask = [1] * (n_tokens + 4)\n",
    "        bidi_labels = ([-100] * (n_tokens + 3)) + [input_ids[i]] \n",
    "        \n",
    "        bidi_input = {\n",
    "            'input_ids': bidi_input_ids,\n",
    "            'attention_mask': bidi_attention_mask,\n",
    "            'labels': bidi_labels\n",
    "        }\n",
    "\n",
    "        # assert len(bidi_input_ids) == len(bidi_attention_mask) == len(bidi_labels)\n",
    "        yield bidi_input\n",
    "\n",
    "    # return mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bidi_inputs(dataset):\n",
    "    for example in dataset:\n",
    "        yield from expand_inputs(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [50260, 50257, 284, 477, 281, 3053, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 9690]}\n",
      "{'input_ids': [50260, 9690, 50257, 477, 281, 3053, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 284]}\n",
      "{'input_ids': [50260, 9690, 284, 50257, 281, 3053, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 477]}\n",
      "{'input_ids': [50260, 9690, 284, 477, 50257, 3053, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 281]}\n",
      "{'input_ids': [50260, 9690, 284, 477, 281, 50257, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 3053]}\n",
      "{'input_ids': [50260, 9690, 284, 477, 281, 3053, 50257, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, 764]}\n",
      "{'input_ids': [50260, 50257, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 41]}\n",
      "{'input_ids': [50260, 41, 50257, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3955]}\n",
      "{'input_ids': [50260, 41, 3955, 50257, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 36992]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 50257, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5781]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 50257, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10725]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 50257, 837, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 45]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 50257, 8100, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 837]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 50257, 23929, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 8100]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 50257, 19535, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23929]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 50257, 47, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 19535]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 50257, 18672, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 47]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 50257, 3525, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 18672]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 50257, 1058, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3525]}\n",
      "{'input_ids': [50260, 41, 3955, 36992, 5781, 10725, 45, 837, 8100, 23929, 19535, 47, 18672, 3525, 50257, 20404, 837, 356, 655, 1392, 257, 1316, 2350, 422, 262, 4141, 1230, 764, 50261, 50259, 50258], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1058]}\n"
     ]
    }
   ],
   "source": [
    "my_iterable_dataset = IterableDataset.from_generator(gen_bidi_inputs, gen_kwargs={\"dataset\": test_set})\n",
    "# my_iterable_dataset = my_iterable_dataset.shuffle(seed=42, buffer_size=100)\n",
    "\n",
    "i = 0\n",
    "for example in my_iterable_dataset:\n",
    "    i += 1\n",
    "    print(example)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_device_name(0))\n",
    "model.to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt')\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    '../models/arisetnrst',\n",
    "    per_device_train_batch_size=8, # change to fit GPU specs\n",
    "    per_device_eval_batch_size=8,\n",
    "    # auto_find_batch_size=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=1,\n",
    "    logging_steps=0.01,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=0.25,\n",
    "    group_by_length=True, # bucketing\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model='loss',\n",
    "    # greater_is_better=False,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
