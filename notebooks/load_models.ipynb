{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading models from **transformers** library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krmkrm/mit/meng/repos/context_and_reduction/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForMaskedLM, GPT2Tokenizer, GPT2Config, GPT2Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import surprisal\n",
    "# from surprisal import AutoHuggingFaceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_BERT(model_path):\n",
    "    model = BertForMaskedLM.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    model_info = {\n",
    "        'model': model,\n",
    "        'tokenizer': tokenizer\n",
    "    }\n",
    "    return model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_GPT2(model_path):\n",
    "    model = AutoHuggingFaceModel.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "    model_info = {\n",
    "        'model': model,\n",
    "        'tokenizer': tokenizer\n",
    "    }\n",
    "    return model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.38.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config()\n",
    "model = GPT2Model(configuration)\n",
    "configuration = model.config\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9663,  0.7905, -0.1253,  ..., -0.9741, -1.5458,  1.7247],\n",
       "         [-1.2045,  0.4355, -0.2053,  ..., -1.2483, -0.3793,  1.1626],\n",
       "         [-2.9977, -0.3331,  0.5655,  ..., -0.6176,  0.0397, -0.1688],\n",
       "         [-2.9592,  0.7808,  0.3051,  ..., -0.7967,  0.0373,  2.7441]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "input_text = \"They have always been\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0232,  0.0910, -0.1171,  ..., -0.1607, -0.0382,  0.0249],\n",
       "         [ 0.1139, -0.2807, -1.0106,  ..., -0.2054,  0.4313,  0.2619],\n",
       "         [-0.0560, -0.0785, -0.1575,  ..., -0.0552, -0.2186, -0.1953],\n",
       "         [-0.3048, -0.1396,  0.7762,  ...,  0.0969, -0.0255, -0.1027]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "input_text = \"They have always been\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits on the floor, and the cat is sitting on the floor.\n",
      "\n",
      "The cat is sitting on the floor.\n",
      "\n",
      "The cat is sitting on the floor.\n",
      "\n",
      "The cat is sitting on the floor.\n",
      "\n",
      "The cat\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "input_text = \"The cat sits on\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(inputs, max_length=50, num_return_sequences=1)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  3797, 10718,   319]])\n",
      "torch.Size([1, 4, 50257])\n",
      "Probability of 'the': 0.3733646869659424\n",
      "Surprisal of 'the': 1.4213426117482204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "input_text = \"The cat sits on\"\n",
    "\n",
    "tokens = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "print(tokens)\n",
    "target_token = tokenizer.encode(\" the\", add_special_tokens=False)[0]\n",
    "\n",
    "\n",
    "with torch.no_grad():  \n",
    "    outputs = model(tokens)\n",
    "    predictions = outputs.logits\n",
    "    print(predictions.shape)\n",
    "\n",
    "logits = predictions[0, -1, :]\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "probability = probabilities[target_token].item()\n",
    "\n",
    "surprisal = -np.log2(probability)\n",
    "\n",
    "print(f\"Probability of 'the': {probability}\")\n",
    "print(f\"Surprisal of 'the': {surprisal}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
