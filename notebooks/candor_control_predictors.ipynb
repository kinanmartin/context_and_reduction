{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating control predictors / random effects from candor_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load candor_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.append(scripts_dir)\n",
    "\n",
    "from candor.create_raw_data import load_conversation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript_output(convo_path: Path):\n",
    "    output_df = load_conversation_tokens(convo_path)\n",
    "    output_df = output_df[output_df.type == 'pronunciation']    \n",
    "    return output_df\n",
    "\n",
    "def load_transcribe_cliffhanger(convo_path: Path):\n",
    "    return pd.read_csv(convo_path / 'transcription/transcript_cliffhanger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_path = Path('../data/candor/sample/0020a0c5-1658-4747-99c1-2839e736b481/')\n",
    "cliffhanger_df = load_transcribe_cliffhanger(convo_path)\n",
    "output_df = load_transcript_output(convo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>utterance</th>\n",
       "      <th>interval</th>\n",
       "      <th>delta</th>\n",
       "      <th>questions</th>\n",
       "      <th>end_question</th>\n",
       "      <th>overlap</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>4.34</td>\n",
       "      <td>190.04</td>\n",
       "      <td>Mhm. Mhm. Just, mm. And Uh huh, mm. Mhm. Mhm. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.70</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>198.34</td>\n",
       "      <td>201.76</td>\n",
       "      <td>Yeah hey I'm gone.</td>\n",
       "      <td>8.30</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>200.64</td>\n",
       "      <td>203.96</td>\n",
       "      <td>Oh good, how are you?</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>204.54</td>\n",
       "      <td>214.66</td>\n",
       "      <td>Yeah yeah I've done a few of these before they...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>205.34</td>\n",
       "      <td>214.56</td>\n",
       "      <td>Yeah. Yeah, so this will be an interesting stu...</td>\n",
       "      <td>-9.32</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2727.21</td>\n",
       "      <td>2728.01</td>\n",
       "      <td>So thank you.</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>2728.29</td>\n",
       "      <td>2731.92</td>\n",
       "      <td>Yeah I get to enjoy your day evening.</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2731.29</td>\n",
       "      <td>2733.00</td>\n",
       "      <td>Yes, you too. Have a good night.</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>2732.59</td>\n",
       "      <td>2734.09</td>\n",
       "      <td>Yeah. Yeah.</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2734.39</td>\n",
       "      <td>2734.66</td>\n",
       "      <td>But</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     turn_id                   speaker    start     stop  \\\n",
       "0          0  5fa072f4f4aa580b63834357     4.34   190.04   \n",
       "1          1  5a73899f9cdd1800017786f0   198.34   201.76   \n",
       "2          2  5fa072f4f4aa580b63834357   200.64   203.96   \n",
       "3          3  5a73899f9cdd1800017786f0   204.54   214.66   \n",
       "4          4  5fa072f4f4aa580b63834357   205.34   214.56   \n",
       "..       ...                       ...      ...      ...   \n",
       "320      320  5fa072f4f4aa580b63834357  2727.21  2728.01   \n",
       "321      321  5a73899f9cdd1800017786f0  2728.29  2731.92   \n",
       "322      322  5fa072f4f4aa580b63834357  2731.29  2733.00   \n",
       "323      323  5a73899f9cdd1800017786f0  2732.59  2734.09   \n",
       "324      324  5fa072f4f4aa580b63834357  2734.39  2734.66   \n",
       "\n",
       "                                             utterance  interval   delta  \\\n",
       "0    Mhm. Mhm. Just, mm. And Uh huh, mm. Mhm. Mhm. ...       NaN  185.70   \n",
       "1                                   Yeah hey I'm gone.      8.30    3.42   \n",
       "2                                Oh good, how are you?     -1.12    3.32   \n",
       "3    Yeah yeah I've done a few of these before they...      0.58   10.12   \n",
       "4    Yeah. Yeah, so this will be an interesting stu...     -9.32    9.22   \n",
       "..                                                 ...       ...     ...   \n",
       "320                                      So thank you.      0.70    0.80   \n",
       "321              Yeah I get to enjoy your day evening.      0.28    3.63   \n",
       "322                   Yes, you too. Have a good night.     -0.63    1.71   \n",
       "323                                        Yeah. Yeah.     -0.41    1.50   \n",
       "324                                                But      0.30    0.27   \n",
       "\n",
       "     questions  end_question  overlap  n_words  \n",
       "0            2         False    False       38  \n",
       "1            0         False    False        5  \n",
       "2            1          True     True        5  \n",
       "3            0         False    False       15  \n",
       "4            0         False     True       14  \n",
       "..         ...           ...      ...      ...  \n",
       "320          0         False    False        3  \n",
       "321          0         False    False        8  \n",
       "322          0         False     True        7  \n",
       "323          0         False     True        2  \n",
       "324          0         False    False        1  \n",
       "\n",
       "[325 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliffhanger_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I absolutely loved it. But yeah, next time I go to Wisconsin, I've already put in my notes, my beer notes that I have to bring back at least a case of spotted cow because it was amazing.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0, len(cliffhanger_df)-1)\n",
    "cliffhanger_df['utterance'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>utterance</th>\n",
       "      <th>confidence</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">0020a0c5-1658-4747-99c1-2839e736b481</th>\n",
       "      <th>0</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.66</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>0.466</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>10.14</td>\n",
       "      <td>10.95</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>0.673</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>12.74</td>\n",
       "      <td>14.36</td>\n",
       "      <td>Just</td>\n",
       "      <td>0.995</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>17.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.468</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>18.74</td>\n",
       "      <td>19.06</td>\n",
       "      <td>And</td>\n",
       "      <td>0.997</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9025</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2732.43</td>\n",
       "      <td>2732.56</td>\n",
       "      <td>good</td>\n",
       "      <td>0.999</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9026</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2732.56</td>\n",
       "      <td>2733.00</td>\n",
       "      <td>night</td>\n",
       "      <td>0.999</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9028</th>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>2732.59</td>\n",
       "      <td>2732.79</td>\n",
       "      <td>Yeah</td>\n",
       "      <td>0.800</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9030</th>\n",
       "      <td>5a73899f9cdd1800017786f0</td>\n",
       "      <td>2733.29</td>\n",
       "      <td>2734.09</td>\n",
       "      <td>Yeah</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>5fa072f4f4aa580b63834357</td>\n",
       "      <td>2734.39</td>\n",
       "      <td>2734.66</td>\n",
       "      <td>But</td>\n",
       "      <td>0.526</td>\n",
       "      <td>pronunciation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7721 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               speaker  \\\n",
       "conversation_id                      turn_id                             \n",
       "0020a0c5-1658-4747-99c1-2839e736b481 0        5fa072f4f4aa580b63834357   \n",
       "                                     2        5fa072f4f4aa580b63834357   \n",
       "                                     4        5fa072f4f4aa580b63834357   \n",
       "                                     6        5fa072f4f4aa580b63834357   \n",
       "                                     8        5fa072f4f4aa580b63834357   \n",
       "...                                                                ...   \n",
       "                                     9025     5fa072f4f4aa580b63834357   \n",
       "                                     9026     5fa072f4f4aa580b63834357   \n",
       "                                     9028     5a73899f9cdd1800017786f0   \n",
       "                                     9030     5a73899f9cdd1800017786f0   \n",
       "                                     9032     5fa072f4f4aa580b63834357   \n",
       "\n",
       "                                                start     stop utterance  \\\n",
       "conversation_id                      turn_id                               \n",
       "0020a0c5-1658-4747-99c1-2839e736b481 0           4.34     4.66       Mhm   \n",
       "                                     2          10.14    10.95       Mhm   \n",
       "                                     4          12.74    14.36      Just   \n",
       "                                     6          17.74    17.95        mm   \n",
       "                                     8          18.74    19.06       And   \n",
       "...                                               ...      ...       ...   \n",
       "                                     9025     2732.43  2732.56      good   \n",
       "                                     9026     2732.56  2733.00     night   \n",
       "                                     9028     2732.59  2732.79      Yeah   \n",
       "                                     9030     2733.29  2734.09      Yeah   \n",
       "                                     9032     2734.39  2734.66       But   \n",
       "\n",
       "                                              confidence           type  \n",
       "conversation_id                      turn_id                             \n",
       "0020a0c5-1658-4747-99c1-2839e736b481 0             0.466  pronunciation  \n",
       "                                     2             0.673  pronunciation  \n",
       "                                     4             0.995  pronunciation  \n",
       "                                     6             0.468  pronunciation  \n",
       "                                     8             0.997  pronunciation  \n",
       "...                                                  ...            ...  \n",
       "                                     9025          0.999  pronunciation  \n",
       "                                     9026          0.999  pronunciation  \n",
       "                                     9028          0.800  pronunciation  \n",
       "                                     9030          1.000  pronunciation  \n",
       "                                     9032          0.526  pronunciation  \n",
       "\n",
       "[7721 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using spacy to get control predictor info\n",
    "\n",
    "All the information should be calculable from a (conversational) turn -level basis, with the exception of frequency, for which a Counter needs to be created from the lemmas of the conversation w.r.t. either all conversations or the current conversation. So, I will first focus on making a function that will calculate and return all necessary control predictors on a turn-level (including information about sentence number and id of word in sentence), then later add in frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmudict_dict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I PRON PRP nsubj X True True 0\n",
      "'ve have AUX VBP aux 'xx False True 1\n",
      "been be AUX VBN aux xxxx True True 1\n",
      "working work VERB VBG ROOT xxxx True False 1\n",
      "on on ADP IN prep xx True True 1\n",
      "the the DET DT det xxx True True 1\n",
      "partially partially ADV RB advmod xxxx True False 0\n",
      "- - PUNCT HYPH punct - False False 0\n",
      "done do VERB VBN amod xxxx True True 1\n",
      "project project NOUN NN poss xxxx True False 0\n",
      "'s 's PART POS case 'x False True 1\n",
      "completion completion NOUN NN pobj xxxx True False 0\n",
      ". . PUNCT . punct . False False 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I've been working on the partially-done project's completion.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop, len(token.whitespace_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlPredictors:\n",
    "    nlp = nlp\n",
    "    cmudict_dict = cmudict_dict\n",
    "    def __init__(self, turn):\n",
    "        \"\"\"\n",
    "        Given a string corresponding to a turn, return dictionary of list of control predictor\n",
    "        values for each WHITESPACE word of the original turn. (whitespace is important so we can\n",
    "        map back to the durations that are annotated in CANDOR)\n",
    "        \"\"\"\n",
    "        doc = nlp(turn)\n",
    "        self.doc = doc\n",
    "        self.turn = turn\n",
    "\n",
    "        self.text = []\n",
    "        self.lemma = []\n",
    "        self.n_chars = []\n",
    "        self.n_syllables = []\n",
    "        self.pos = []\n",
    "        self.stopword = []\n",
    "        self.mtw = [] # is word a multi-token word? ex: \"I've\", but not \"he,\" (punct)\n",
    "        \n",
    "        self.sentence_id_in_turn = []\n",
    "        self.word_id_in_sentence = []\n",
    "\n",
    "        self.n_whitespace_words = 0\n",
    "        skip_this_token = False\n",
    "        sentence_id = -1\n",
    "        word_id = 0\n",
    "        for idx, token in enumerate(doc):\n",
    "            if skip_this_token:\n",
    "                if token.whitespace_:\n",
    "                    skip_this_token = False\n",
    "                continue\n",
    "\n",
    "            # print(token)\n",
    "            \n",
    "            self.text.append(token.text)\n",
    "            self.lemma.append(token.lemma_)\n",
    "            self.n_chars.append(len(token.text))\n",
    "            self.n_syllables.append(self.word_syllable_count(token.lemma_.lower()))\n",
    "            self.pos.append(token.pos_)\n",
    "            self.stopword.append(token.is_stop)\n",
    "\n",
    "            self.n_whitespace_words += 1\n",
    "\n",
    "            if token.is_sent_start:\n",
    "                sentence_id += 1\n",
    "                word_id = 0\n",
    "\n",
    "            self.sentence_id_in_turn.append(sentence_id)\n",
    "            self.word_id_in_sentence.append(word_id)\n",
    "\n",
    "            word_id += 1\n",
    "            \n",
    "            is_mtw = False\n",
    "            if not token.whitespace_:\n",
    "                skip_this_token = True\n",
    "                if idx + 1 < len(doc) - 1:\n",
    "                    # the current token is a multitoken word if there's no whitespace between\n",
    "                    # this token and the next, and the next token is not punctuation\n",
    "                    is_mtw = (doc[idx+1].pos_ != 'PUNCT') #and doc[idx+1].text != '-'\n",
    "\n",
    "            self.mtw.append(is_mtw)\n",
    "        \n",
    "        assert len(turn.split(' ')) == self.n_whitespace_words, f\"mismatch in spacy tokenization, actual whitespace: {len(turn.split(' '))} != spacy whitespace: {self.n_whitespace_words}\"\n",
    "\n",
    "    def word_syllable_count(self, word) -> int:\n",
    "        if word in self.cmudict_dict:\n",
    "            # Return the minimum count if multiple pronunciations exist\n",
    "            return min([len([y for y in x if y[-1].isdigit()]) for x in self.cmudict_dict[word]])\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for k, v in vars(self).items():\n",
    "            if isinstance(v, list):\n",
    "                yield k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "absolutely\n",
      "loved\n",
      "it\n",
      "But\n",
      "yeah\n",
      "next\n",
      "time\n",
      "I\n",
      "go\n",
      "to\n",
      "Wisconsin\n",
      "I\n",
      "already\n",
      "put\n",
      "in\n",
      "my\n",
      "notes\n",
      "my\n",
      "beer\n",
      "notes\n",
      "that\n",
      "I\n",
      "have\n",
      "to\n",
      "bring\n",
      "back\n",
      "at\n",
      "least\n",
      "a\n",
      "case\n",
      "of\n",
      "spotted\n",
      "cow\n",
      "because\n",
      "it\n",
      "was\n",
      "amazing\n",
      "doc I absolutely loved it. But yeah, next time I go to Wisconsin, I've already put in my notes, my beer notes that I have to bring back at least a case of spotted cow because it was amazing.\n",
      "turn I absolutely loved it. But yeah, next time I go to Wisconsin, I've already put in my notes, my beer notes that I have to bring back at least a case of spotted cow because it was amazing.\n",
      "text ['I', 'absolutely', 'loved', 'it', 'But', 'yeah', 'next', 'time', 'I', 'go', 'to', 'Wisconsin', 'I', 'already', 'put', 'in', 'my', 'notes', 'my', 'beer', 'notes', 'that', 'I', 'have', 'to', 'bring', 'back', 'at', 'least', 'a', 'case', 'of', 'spotted', 'cow', 'because', 'it', 'was', 'amazing']\n",
      "lemma ['I', 'absolutely', 'love', 'it', 'but', 'yeah', 'next', 'time', 'I', 'go', 'to', 'Wisconsin', 'I', 'already', 'put', 'in', 'my', 'note', 'my', 'beer', 'note', 'that', 'I', 'have', 'to', 'bring', 'back', 'at', 'least', 'a', 'case', 'of', 'spotted', 'cow', 'because', 'it', 'be', 'amazing']\n",
      "n_chars [1, 10, 5, 2, 3, 4, 4, 4, 1, 2, 2, 9, 1, 7, 3, 2, 2, 5, 2, 4, 5, 4, 1, 4, 2, 5, 4, 2, 5, 1, 4, 2, 7, 3, 7, 2, 3, 7]\n",
      "n_syllables [1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3]\n",
      "pos ['PRON', 'ADV', 'VERB', 'PRON', 'CCONJ', 'INTJ', 'ADJ', 'NOUN', 'PRON', 'VERB', 'ADP', 'PROPN', 'PRON', 'ADV', 'VERB', 'ADP', 'PRON', 'NOUN', 'PRON', 'NOUN', 'VERB', 'SCONJ', 'PRON', 'VERB', 'PART', 'VERB', 'ADV', 'ADV', 'ADJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'SCONJ', 'PRON', 'AUX', 'ADJ']\n",
      "stopword [True, False, False, True, True, False, True, False, True, True, True, False, True, True, True, True, True, False, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, True, True, False]\n",
      "mtw [False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "sentence_id_in_turn [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "word_id_in_sentence [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
      "n_whitespace_words 38\n"
     ]
    }
   ],
   "source": [
    "text = \"I've been diligently, strongly, hardly, we've, been working on the partially-done project's completion\"\n",
    "text = \"I absolutely loved it. But yeah, next time I go to Wisconsin, I've already put in my notes, my beer notes that I have to bring back at least a case of spotted cow because it was amazing.\"\n",
    "text_control_predictors = ControlPredictors(text)\n",
    "for k, v in vars(text_control_predictors).items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I': 343,\n",
       "         'like': 291,\n",
       "         'the': 189,\n",
       "         'and': 186,\n",
       "         'to': 173,\n",
       "         'Yeah': 153,\n",
       "         'a': 150,\n",
       "         'you': 144,\n",
       "         'of': 138,\n",
       "         'know': 126,\n",
       "         'yeah': 95,\n",
       "         'so': 92,\n",
       "         'Oh': 91,\n",
       "         'that': 90,\n",
       "         'it': 88,\n",
       "         'in': 82,\n",
       "         \"it's\": 79,\n",
       "         'we': 74,\n",
       "         'just': 68,\n",
       "         'was': 68,\n",
       "         'my': 67,\n",
       "         'is': 66,\n",
       "         'Mhm': 60,\n",
       "         'So': 58,\n",
       "         'for': 56,\n",
       "         'have': 51,\n",
       "         'as': 50,\n",
       "         \"don't\": 48,\n",
       "         'do': 48,\n",
       "         'Uh': 46,\n",
       "         'all': 45,\n",
       "         'And': 44,\n",
       "         'but': 44,\n",
       "         'really': 42,\n",
       "         'kind': 41,\n",
       "         \"I'm\": 40,\n",
       "         'right': 38,\n",
       "         'because': 37,\n",
       "         'huh': 36,\n",
       "         'at': 36,\n",
       "         'are': 34,\n",
       "         'what': 34,\n",
       "         'be': 33,\n",
       "         \"that's\": 32,\n",
       "         'But': 31,\n",
       "         'Okay': 30,\n",
       "         'this': 29,\n",
       "         'there': 29,\n",
       "         'get': 29,\n",
       "         'about': 29,\n",
       "         'not': 28,\n",
       "         'been': 28,\n",
       "         'uh': 27,\n",
       "         'go': 27,\n",
       "         'with': 27,\n",
       "         'going': 26,\n",
       "         'had': 26,\n",
       "         'got': 25,\n",
       "         'kids': 24,\n",
       "         'up': 24,\n",
       "         'now': 24,\n",
       "         'good': 23,\n",
       "         'time': 23,\n",
       "         'me': 23,\n",
       "         'want': 23,\n",
       "         'one': 22,\n",
       "         'no': 22,\n",
       "         \"we're\": 22,\n",
       "         'work': 21,\n",
       "         'out': 21,\n",
       "         'would': 21,\n",
       "         'actually': 20,\n",
       "         'little': 20,\n",
       "         'think': 20,\n",
       "         'or': 20,\n",
       "         'well': 20,\n",
       "         'our': 20,\n",
       "         \"It's\": 20,\n",
       "         'too': 18,\n",
       "         'year': 18,\n",
       "         'on': 18,\n",
       "         \"I've\": 17,\n",
       "         'when': 17,\n",
       "         'God': 17,\n",
       "         'can': 17,\n",
       "         'then': 17,\n",
       "         'Yes': 17,\n",
       "         'here': 17,\n",
       "         'how': 16,\n",
       "         'if': 16,\n",
       "         'some': 16,\n",
       "         'mm': 15,\n",
       "         'your': 15,\n",
       "         'from': 15,\n",
       "         'lot': 15,\n",
       "         'love': 15,\n",
       "         'stuff': 15,\n",
       "         \"That's\": 15,\n",
       "         'Right': 14,\n",
       "         'um': 14,\n",
       "         'very': 14,\n",
       "         'them': 14,\n",
       "         'they': 13,\n",
       "         'mean': 13,\n",
       "         'next': 13,\n",
       "         'fish': 13,\n",
       "         'live': 13,\n",
       "         'thing': 12,\n",
       "         'names': 12,\n",
       "         'years': 12,\n",
       "         'more': 12,\n",
       "         'gonna': 12,\n",
       "         'Um': 12,\n",
       "         'were': 12,\n",
       "         'he': 12,\n",
       "         \"they're\": 11,\n",
       "         'cool': 11,\n",
       "         'school': 11,\n",
       "         'okay': 11,\n",
       "         'much': 11,\n",
       "         'being': 11,\n",
       "         'say': 11,\n",
       "         'everything': 11,\n",
       "         'pretty': 10,\n",
       "         'by': 10,\n",
       "         'did': 10,\n",
       "         \"there's\": 10,\n",
       "         'any': 10,\n",
       "         'make': 10,\n",
       "         'only': 10,\n",
       "         'back': 10,\n",
       "         'these': 9,\n",
       "         'doing': 9,\n",
       "         'even': 9,\n",
       "         'she': 9,\n",
       "         'myself': 9,\n",
       "         'things': 9,\n",
       "         'night': 9,\n",
       "         'Like': 9,\n",
       "         'Well': 9,\n",
       "         'Wisconsin': 9,\n",
       "         \"you're\": 9,\n",
       "         'Iowa': 9,\n",
       "         'No': 9,\n",
       "         'every': 9,\n",
       "         'over': 9,\n",
       "         'You': 9,\n",
       "         'where': 9,\n",
       "         'will': 8,\n",
       "         'yes': 8,\n",
       "         'those': 8,\n",
       "         'sounds': 8,\n",
       "         'way': 8,\n",
       "         'The': 8,\n",
       "         'last': 8,\n",
       "         'probably': 8,\n",
       "         'ever': 8,\n",
       "         'down': 8,\n",
       "         'A': 8,\n",
       "         'nice': 8,\n",
       "         'went': 8,\n",
       "         'What': 7,\n",
       "         'an': 7,\n",
       "         'few': 7,\n",
       "         'before': 7,\n",
       "         'bad': 7,\n",
       "         'yep': 7,\n",
       "         'getting': 7,\n",
       "         'kid': 7,\n",
       "         'their': 7,\n",
       "         'her': 7,\n",
       "         'said': 7,\n",
       "         'us': 7,\n",
       "         \"can't\": 7,\n",
       "         'keep': 7,\n",
       "         'least': 7,\n",
       "         'around': 7,\n",
       "         'foam': 7,\n",
       "         'than': 7,\n",
       "         'It': 7,\n",
       "         'people': 7,\n",
       "         'That': 7,\n",
       "         'beer': 7,\n",
       "         'Moines': 7,\n",
       "         'him': 7,\n",
       "         'Minnesota': 7,\n",
       "         'october': 7,\n",
       "         'super': 7,\n",
       "         'interesting': 6,\n",
       "         'first': 6,\n",
       "         'bit': 6,\n",
       "         'oh': 6,\n",
       "         'used': 6,\n",
       "         'name': 6,\n",
       "         'something': 6,\n",
       "         'two': 6,\n",
       "         'fun': 6,\n",
       "         'man': 6,\n",
       "         'see': 6,\n",
       "         'great': 6,\n",
       "         'off': 6,\n",
       "         'new': 6,\n",
       "         'seems': 6,\n",
       "         'could': 6,\n",
       "         'why': 6,\n",
       "         'working': 6,\n",
       "         'also': 6,\n",
       "         'always': 6,\n",
       "         'which': 6,\n",
       "         'spotted': 6,\n",
       "         'border': 6,\n",
       "         'happy': 6,\n",
       "         'candy': 6,\n",
       "         'has': 6,\n",
       "         'movie': 6,\n",
       "         'done': 5,\n",
       "         \"we've\": 5,\n",
       "         'today': 5,\n",
       "         'other': 5,\n",
       "         'many': 5,\n",
       "         'awesome': 5,\n",
       "         \"they've\": 5,\n",
       "         'favorite': 5,\n",
       "         'same': 5,\n",
       "         'oldest': 5,\n",
       "         'made': 5,\n",
       "         'wanted': 5,\n",
       "         'different': 5,\n",
       "         'middle': 5,\n",
       "         'family': 5,\n",
       "         'able': 5,\n",
       "         'trying': 5,\n",
       "         'neighbors': 5,\n",
       "         'best': 5,\n",
       "         'pumpkin': 5,\n",
       "         'am': 5,\n",
       "         'set': 5,\n",
       "         'until': 5,\n",
       "         'sure': 5,\n",
       "         'cow': 5,\n",
       "         'take': 5,\n",
       "         'feel': 5,\n",
       "         'We': 5,\n",
       "         'guess': 4,\n",
       "         'sort': 4,\n",
       "         'home': 4,\n",
       "         'enjoy': 4,\n",
       "         'while': 4,\n",
       "         'might': 4,\n",
       "         'seven': 4,\n",
       "         'mind': 4,\n",
       "         'anyway': 4,\n",
       "         'fine': 4,\n",
       "         'high': 4,\n",
       "         'soon': 4,\n",
       "         'generic': 4,\n",
       "         'My': 4,\n",
       "         'stand': 4,\n",
       "         'sorry': 4,\n",
       "         'midwesterner': 4,\n",
       "         'sports': 4,\n",
       "         \"let's\": 4,\n",
       "         'partner': 4,\n",
       "         'big': 4,\n",
       "         'baking': 4,\n",
       "         'week': 4,\n",
       "         'door': 4,\n",
       "         'whatever': 4,\n",
       "         'roll': 4,\n",
       "         'tons': 4,\n",
       "         'crazy': 4,\n",
       "         'factory': 4,\n",
       "         'phone': 4,\n",
       "         'makes': 4,\n",
       "         'guy': 4,\n",
       "         'tell': 4,\n",
       "         'hilarious': 4,\n",
       "         'manufacturing': 4,\n",
       "         '10': 4,\n",
       "         'almost': 4,\n",
       "         'guys': 4,\n",
       "         'either': 4,\n",
       "         'game': 4,\n",
       "         'whole': 4,\n",
       "         'into': 4,\n",
       "         'creative': 4,\n",
       "         'allowed': 4,\n",
       "         'works': 4,\n",
       "         'des': 4,\n",
       "         \"he's\": 4,\n",
       "         'called': 4,\n",
       "         'Milwaukee': 4,\n",
       "         'wearing': 4,\n",
       "         'food': 4,\n",
       "         'already': 4,\n",
       "         'prettier': 4,\n",
       "         'point': 4,\n",
       "         'look': 4,\n",
       "         'never': 4,\n",
       "         'thank': 4,\n",
       "         'certain': 4,\n",
       "         'day': 4,\n",
       "         'Halloween': 4,\n",
       "         'results': 4,\n",
       "         'come': 4,\n",
       "         'hand': 4,\n",
       "         'bummed': 4,\n",
       "         'believe': 4,\n",
       "         'recommend': 4,\n",
       "         'Really': 3,\n",
       "         'study': 3,\n",
       "         'hard': 3,\n",
       "         'swear': 3,\n",
       "         'sleep': 3,\n",
       "         'quite': 3,\n",
       "         'hear': 3,\n",
       "         'number': 3,\n",
       "         'far': 3,\n",
       "         'heard': 3,\n",
       "         'hours': 3,\n",
       "         'Mm': 3,\n",
       "         'asking': 3,\n",
       "         'wow': 3,\n",
       "         \"didn't\": 3,\n",
       "         'most': 3,\n",
       "         'suddenly': 3,\n",
       "         'team': 3,\n",
       "         'All': 3,\n",
       "         'Nice': 3,\n",
       "         'follow': 3,\n",
       "         'second': 3,\n",
       "         'cowboys': 3,\n",
       "         'someone': 3,\n",
       "         'house': 3,\n",
       "         'bought': 3,\n",
       "         'everyone': 3,\n",
       "         'friends': 3,\n",
       "         'cake': 3,\n",
       "         'fall': 3,\n",
       "         'midwestern': 3,\n",
       "         'once': 3,\n",
       "         'rest': 3,\n",
       "         'does': 3,\n",
       "         'started': 3,\n",
       "         'still': 3,\n",
       "         'pillows': 3,\n",
       "         'please': 3,\n",
       "         'who': 3,\n",
       "         'end': 3,\n",
       "         'god': 3,\n",
       "         'joke': 3,\n",
       "         'remember': 3,\n",
       "         'stay': 3,\n",
       "         'exactly': 3,\n",
       "         'design': 3,\n",
       "         'board': 3,\n",
       "         'alright': 3,\n",
       "         'need': 3,\n",
       "         'ago': 3,\n",
       "         'talking': 3,\n",
       "         'essentially': 3,\n",
       "         'amazing': 3,\n",
       "         'hoping': 3,\n",
       "         'thinking': 3,\n",
       "         'totally': 3,\n",
       "         'came': 3,\n",
       "         'local': 3,\n",
       "         'fry': 3,\n",
       "         'place': 3,\n",
       "         'hall': 3,\n",
       "         'staff': 3,\n",
       "         'fried': 3,\n",
       "         'months': 3,\n",
       "         'breweries': 3,\n",
       "         'put': 3,\n",
       "         'plan': 3,\n",
       "         'Northwood': 3,\n",
       "         'part': 3,\n",
       "         'reason': 3,\n",
       "         'state': 3,\n",
       "         'better': 3,\n",
       "         'another': 3,\n",
       "         'life': 3,\n",
       "         'bless': 3,\n",
       "         'heart': 3,\n",
       "         'month': 3,\n",
       "         'full': 3,\n",
       "         'test': 3,\n",
       "         'park': 3,\n",
       "         'books': 3,\n",
       "         'terrible': 3,\n",
       "         'thought': 3,\n",
       "         'window': 3,\n",
       "         'saw': 3,\n",
       "         'normally': 3,\n",
       "         'sucks': 3,\n",
       "         'again': 3,\n",
       "         'hospital': 3,\n",
       "         'Des': 3,\n",
       "         'P': 3,\n",
       "         'Just': 2,\n",
       "         'hey': 2,\n",
       "         'Is': 2,\n",
       "         'crappy': 2,\n",
       "         'sick': 2,\n",
       "         \"hasn't\": 2,\n",
       "         'feeling': 2,\n",
       "         'spread': 2,\n",
       "         'cute': 2,\n",
       "         'such': 2,\n",
       "         'job': 2,\n",
       "         'girls': 2,\n",
       "         'give': 2,\n",
       "         'both': 2,\n",
       "         'late': 2,\n",
       "         'lucky': 2,\n",
       "         'old': 2,\n",
       "         'three': 2,\n",
       "         'nonprofit': 2,\n",
       "         'organize': 2,\n",
       "         'worked': 2,\n",
       "         'youngest': 2,\n",
       "         'raven': 2,\n",
       "         'ahead': 2,\n",
       "         \"wife's\": 2,\n",
       "         'together': 2,\n",
       "         \"I'll\": 2,\n",
       "         'girl': 2,\n",
       "         'common': 2,\n",
       "         'surrounded': 2,\n",
       "         'Caitlin': 2,\n",
       "         'cannot': 2,\n",
       "         'Katie': 2,\n",
       "         'Sorry': 2,\n",
       "         'siblings': 2,\n",
       "         'typical': 2,\n",
       "         'parents': 2,\n",
       "         'Green': 2,\n",
       "         'Bay': 2,\n",
       "         'john': 2,\n",
       "         'although': 2,\n",
       "         'personally': 2,\n",
       "         'bunch': 2,\n",
       "         'ton': 2,\n",
       "         'watching': 2,\n",
       "         'emotionally': 2,\n",
       "         'invested': 2,\n",
       "         'baked': 2,\n",
       "         'goods': 2,\n",
       "         'lived': 2,\n",
       "         'outside': 2,\n",
       "         'since': 2,\n",
       "         'They': 2,\n",
       "         'houses': 2,\n",
       "         'rolls': 2,\n",
       "         'social': 2,\n",
       "         'OK': 2,\n",
       "         \"what's\": 2,\n",
       "         'cheese': 2,\n",
       "         'Probably': 2,\n",
       "         'talk': 2,\n",
       "         'living': 2,\n",
       "         'packing': 2,\n",
       "         'materials': 2,\n",
       "         'headliner': 2,\n",
       "         'car': 2,\n",
       "         'pillow': 2,\n",
       "         '$10': 2,\n",
       "         'pay': 2,\n",
       "         'thrills': 2,\n",
       "         'graphic': 2,\n",
       "         'curious': 2,\n",
       "         'quality': 2,\n",
       "         'control': 2,\n",
       "         'production': 2,\n",
       "         'line': 2,\n",
       "         'amount': 2,\n",
       "         'between': 2,\n",
       "         'gosh': 2,\n",
       "         'age': 2,\n",
       "         'often': 2,\n",
       "         '30': 2,\n",
       "         'slapping': 2,\n",
       "         'logo': 2,\n",
       "         'Cuzzi': 2,\n",
       "         'excited': 2,\n",
       "         'event': 2,\n",
       "         'constructing': 2,\n",
       "         'book': 2,\n",
       "         'completely': 2,\n",
       "         'throw': 2,\n",
       "         'must': 2,\n",
       "         'wish': 2,\n",
       "         'though': 2,\n",
       "         'future': 2,\n",
       "         'silk': 2,\n",
       "         'screen': 2,\n",
       "         'idea': 2,\n",
       "         'studio': 2,\n",
       "         'garage': 2,\n",
       "         'correct': 2,\n",
       "         'actual': 2,\n",
       "         'spring': 2,\n",
       "         'perfect': 2,\n",
       "         '32°': 2,\n",
       "         'light': 2,\n",
       "         'seem': 2,\n",
       "         'fries': 2,\n",
       "         'wife': 2,\n",
       "         'service': 2,\n",
       "         'wedding': 2,\n",
       "         'lives': 2,\n",
       "         'texas': 2,\n",
       "         'several': 2,\n",
       "         'friday': 2,\n",
       "         'This': 2,\n",
       "         'serb': 2,\n",
       "         'large': 2,\n",
       "         'wait': 2,\n",
       "         'formal': 2,\n",
       "         'suits': 2,\n",
       "         'tuxedos': 2,\n",
       "         'dress': 2,\n",
       "         'eating': 2,\n",
       "         'mhm': 2,\n",
       "         'incredible': 2,\n",
       "         'making': 2,\n",
       "         'looked': 2,\n",
       "         'couple': 2,\n",
       "         'craft': 2,\n",
       "         'notes': 2,\n",
       "         'literally': 2,\n",
       "         'anywhere': 2,\n",
       "         'trip': 2,\n",
       "         'fourth': 2,\n",
       "         'describe': 2,\n",
       "         'small': 2,\n",
       "         'ah': 2,\n",
       "         'world': 2,\n",
       "         'starts': 2,\n",
       "         'gets': 2,\n",
       "         'friend': 2,\n",
       "         'mine': 2,\n",
       "         'gorgeous': 2,\n",
       "         'Maybe': 2,\n",
       "         'feels': 2,\n",
       "         'through': 2,\n",
       "         'moved': 2,\n",
       "         'less': 2,\n",
       "         'Federal': 2,\n",
       "         'facility': 2,\n",
       "         'across': 2,\n",
       "         'call': 2,\n",
       "         'ignored': 2,\n",
       "         'midwest': 2,\n",
       "         'charm': 2,\n",
       "         'freezing': 2,\n",
       "         'cold': 2,\n",
       "         '32': 2,\n",
       "         'weird': 2,\n",
       "         'trick': 2,\n",
       "         'bummer': 2,\n",
       "         'tested': 2,\n",
       "         'positive': 2,\n",
       "         'covid': 2,\n",
       "         'under': 2,\n",
       "         'waiting': 2,\n",
       "         'ended': 2,\n",
       "         'block': 2,\n",
       "         'glass': 2,\n",
       "         'his': 2,\n",
       "         'fellow': 2,\n",
       "         \"beggar's\": 2,\n",
       "         'bigger': 2,\n",
       "         'Jurassic': 2,\n",
       "         'dressed': 2,\n",
       "         'dinosaur': 2,\n",
       "         'brontosaurus': 2,\n",
       "         'let': 2,\n",
       "         'costumes': 2,\n",
       "         'huge': 2,\n",
       "         'picture': 2,\n",
       "         \"couldn't\": 2,\n",
       "         'watch': 2,\n",
       "         'after': 2,\n",
       "         'birthday': 2,\n",
       "         'planning': 2,\n",
       "         'intense': 2,\n",
       "         'happens': 2,\n",
       "         'tough': 2,\n",
       "         'slightly': 2,\n",
       "         'imagine': 2,\n",
       "         'schedule': 2,\n",
       "         'daycare': 2,\n",
       "         'expensive': 2,\n",
       "         'area': 2,\n",
       "         'horribly': 2,\n",
       "         'dropped': 2,\n",
       "         'adult': 2,\n",
       "         'lunchables': 2,\n",
       "         \"she's\": 2,\n",
       "         'wrap': 2,\n",
       "         'theater': 2,\n",
       "         'limit': 2,\n",
       "         'conversations': 2,\n",
       "         'dish': 2,\n",
       "         'Great': 1,\n",
       "         'gone': 1,\n",
       "         'chad': 1,\n",
       "         'There': 1,\n",
       "         'excellent': 1,\n",
       "         'Feel': 1,\n",
       "         'suppose': 1,\n",
       "         \"kid's\": 1,\n",
       "         'shared': 1,\n",
       "         'thanks': 1,\n",
       "         'Tiny': 1,\n",
       "         'firm': 1,\n",
       "         'sponge': 1,\n",
       "         'meant': 1,\n",
       "         'germs': 1,\n",
       "         'viruses': 1,\n",
       "         'everywhere': 1,\n",
       "         'sent': 1,\n",
       "         '22': 1,\n",
       "         'yet': 1,\n",
       "         'staying': 1,\n",
       "         'keeping': 1,\n",
       "         'ready': 1,\n",
       "         'Do': 1,\n",
       "         'program': 1,\n",
       "         'director': 1,\n",
       "         'nieces': 1,\n",
       "         'elementary': 1,\n",
       "         'Pepper': 1,\n",
       "         'Those': 1,\n",
       "         'unique': 1,\n",
       "         'Our': 1,\n",
       "         'discern': 1,\n",
       "         'ex': 1,\n",
       "         'backstory': 1,\n",
       "         'ours': 1,\n",
       "         'pregnant': 1,\n",
       "         'decided': 1,\n",
       "         'boy': 1,\n",
       "         'exchange': 1,\n",
       "         'doctor': 1,\n",
       "         'spit': 1,\n",
       "         'apparently': 1,\n",
       "         '#': 1,\n",
       "         'popular': 1,\n",
       "         'Italy': 1,\n",
       "         '1997': 1,\n",
       "         'born': 1,\n",
       "         '88': 1,\n",
       "         'throughout': 1,\n",
       "         'toddlers': 1,\n",
       "         'named': 1,\n",
       "         'refused': 1,\n",
       "         'basic': 1,\n",
       "         'suburban': 1,\n",
       "         'softball': 1,\n",
       "         'general': 1,\n",
       "         'tale': 1,\n",
       "         \"haven't\": 1,\n",
       "         'minded': 1,\n",
       "         'four': 1,\n",
       "         'sense': 1,\n",
       "         'uniqueness': 1,\n",
       "         'At': 1,\n",
       "         'locked': 1,\n",
       "         'quote': 1,\n",
       "         'Packers': 1,\n",
       "         'How': 1,\n",
       "         'cut': 1,\n",
       "         'Why': 1,\n",
       "         'sound': 1,\n",
       "         'quick': 1,\n",
       "         'tend': 1,\n",
       "         'fan': 1,\n",
       "         'whenever': 1,\n",
       "         'competitions': 1,\n",
       "         'british': 1,\n",
       "         'bake': 1,\n",
       "         'scones': 1,\n",
       "         'hmm': 1,\n",
       "         'victorious': 1,\n",
       "         'fund': 1,\n",
       "         'episode': 1,\n",
       "         'netflix': 1,\n",
       "         'jesse': 1,\n",
       "         'Super': 1,\n",
       "         'Bowl': 1,\n",
       "         'weekend': 1,\n",
       "         'slowly': 1,\n",
       "         \"who've\": 1,\n",
       "         'korean': 1,\n",
       "         'war': 1,\n",
       "         'longest': 1,\n",
       "         'sudden': 1,\n",
       "         'figured': 1,\n",
       "         'bribe': 1,\n",
       "         'figure': 1,\n",
       "         'loves': 1,\n",
       "         'walking': 1,\n",
       "         'customer': 1,\n",
       "         'experiment': 1,\n",
       "         'win': 1,\n",
       "         'pumping': 1,\n",
       "         'roller': 1,\n",
       "         'swiss': 1,\n",
       "         'chocolate': 1,\n",
       "         'rolled': 1,\n",
       "         'cream': 1,\n",
       "         'frosting': 1,\n",
       "         'tastes': 1,\n",
       "         'dreams': 1,\n",
       "         'Starlight': 1,\n",
       "         'dessert': 1,\n",
       "         'start': 1,\n",
       "         'swapping': 1,\n",
       "         'recipes': 1,\n",
       "         'avenue': 1,\n",
       "         'switch': 1,\n",
       "         'gears': 1,\n",
       "         'otherwise': 1,\n",
       "         'pie': 1,\n",
       "         'Phone': 1,\n",
       "         'fo': 1,\n",
       "         'phones': 1,\n",
       "         'After': 1,\n",
       "         'US': 1,\n",
       "         'following': 1,\n",
       "         'explain': 1,\n",
       "         'headliners': 1,\n",
       "         'Deere': 1,\n",
       "         'tractors': 1,\n",
       "         'bobcat': 1,\n",
       "         'caterpillar': 1,\n",
       "         'tractor': 1,\n",
       "         \"isn't\": 1,\n",
       "         'One': 1,\n",
       "         'companies': 1,\n",
       "         'foams': 1,\n",
       "         'Joann': 1,\n",
       "         'fabrics': 1,\n",
       "         'bears': 1,\n",
       "         'infomercial': 1,\n",
       "         'pil': 1,\n",
       "         'ho': 1,\n",
       "         'weapon': 1,\n",
       "         'creepiest': 1,\n",
       "         'He': 1,\n",
       "         'insider': 1,\n",
       "         'secrets': 1,\n",
       "         'Pillow': 1,\n",
       "         'Mediocre': 1,\n",
       "         'worth': 1,\n",
       "         'price': 1,\n",
       "         \"won't\": 1,\n",
       "         'Now': 1,\n",
       "         'knows': 1,\n",
       "         'funny': 1,\n",
       "         'sad': 1,\n",
       "         'ask': 1,\n",
       "         'cause': 1,\n",
       "         'Jacqueline': 1,\n",
       "         'trades': 1,\n",
       "         'barista': 1,\n",
       "         'Polaris': 1,\n",
       "         'executive': 1,\n",
       "         'members': 1,\n",
       "         'designer': 1,\n",
       "         'resume': 1,\n",
       "         'looks': 1,\n",
       "         'regular': 1,\n",
       "         'regularly': 1,\n",
       "         'mindless': 1,\n",
       "         'Remember': 1,\n",
       "         'fair': 1,\n",
       "         'turnover': 1,\n",
       "         '80s': 1,\n",
       "         'older': 1,\n",
       "         'average': 1,\n",
       "         'employee': 1,\n",
       "         '60': 1,\n",
       "         'close': 1,\n",
       "         'True': 1,\n",
       "         'generation': 1,\n",
       "         'found': 1,\n",
       "         \"you'll\": 1,\n",
       "         'retirement': 1,\n",
       "         'wonder': 1,\n",
       "         'bracket': 1,\n",
       "         'demographic': 1,\n",
       "         'finding': 1,\n",
       "         'jobs': 1,\n",
       "         'necessarily': 1,\n",
       "         'allows': 1,\n",
       "         'sixties': 1,\n",
       "         'naturally': 1,\n",
       "         'inclined': 1,\n",
       "         'bounce': 1,\n",
       "         'graphics': 1,\n",
       "         'promotional': 1,\n",
       "         'product': 1,\n",
       "         'company': 1,\n",
       "         'simple': 1,\n",
       "         \"someone's\": 1,\n",
       "         'creating': 1,\n",
       "         'designs': 1,\n",
       "         't': 1,\n",
       "         'shirts': 1,\n",
       "         'printed': 1,\n",
       "         'projects': 1,\n",
       "         'chew': 1,\n",
       "         'versus': 1,\n",
       "         'holidays': 1,\n",
       "         'clients': 1,\n",
       "         'organizing': 1,\n",
       "         \"Didn't\": 1,\n",
       "         'putting': 1,\n",
       "         'kit': 1,\n",
       "         'families': 1,\n",
       "         'outdoor': 1,\n",
       "         'distance': 1,\n",
       "         'booklet': 1,\n",
       "         'rules': 1,\n",
       "         'designing': 1,\n",
       "         'cover': 1,\n",
       "         'taken': 1,\n",
       "         'apart': 1,\n",
       "         'chutes': 1,\n",
       "         'ladders': 1,\n",
       "         'esque': 1,\n",
       "         'anytime': 1,\n",
       "         'opportunity': 1,\n",
       "         'overthink': 1,\n",
       "         'project': 1,\n",
       "         'thrilled': 1,\n",
       "         'effort': 1,\n",
       "         'possible': 1,\n",
       "         '3.5': 1,\n",
       "         '20%': 1,\n",
       "         '40-50%': 1,\n",
       "         'balance': 1,\n",
       "         'brainless': 1,\n",
       "         'intensity': 1,\n",
       "         'discovered': 1,\n",
       "         'expanding': 1,\n",
       "         'directions': 1,\n",
       "         'printing': 1,\n",
       "         'Jack': 1,\n",
       "         'clothes': 1,\n",
       "         'covered': 1,\n",
       "         'ink': 1,\n",
       "         'print': 1,\n",
       "         'boss': 1,\n",
       "         'hands': 1,\n",
       "         'printmaking': 1,\n",
       "         'wheelhouse': 1,\n",
       "         'supposed': 1,\n",
       "         'happen': 1,\n",
       "         'Damn': 1,\n",
       "         'Thanks': 1,\n",
       "         'silkscreen': 1,\n",
       "         'appeal': 1,\n",
       "         '32°.': 1,\n",
       "         'random': 1,\n",
       "         'question': 1,\n",
       "         'Wisconsinite': 1,\n",
       "         'frequently': 1,\n",
       "         'attend': 1,\n",
       "         'wrong': 1,\n",
       "         'picky': 1,\n",
       "         'freezer': 1,\n",
       "         'ice': 1,\n",
       "         'fishing': 1,\n",
       "         'buddy': 1,\n",
       "         'bar': 1,\n",
       "         'When': 1,\n",
       "         'meals': 1,\n",
       "         'strangest': 1,\n",
       "         'environment': 1,\n",
       "         'eaten': 1,\n",
       "         'code': 1,\n",
       "         'relaxed': 1,\n",
       "         '40%': 1,\n",
       "         'exaggerating': 1,\n",
       "         'green': 1,\n",
       "         'bay': 1,\n",
       "         'packers': 1,\n",
       "         'gear': 1,\n",
       "         'eye': 1,\n",
       "         'Munich': 1,\n",
       "         'selection': 1,\n",
       "         'ranged': 1,\n",
       "         'Sarah': 1,\n",
       "         'McLachlan': 1,\n",
       "         'traditional': 1,\n",
       "         'Serbian': 1,\n",
       "         'folk': 1,\n",
       "         'music': 1,\n",
       "         'strange': 1,\n",
       "         'drinking': 1,\n",
       "         'possibly': 1,\n",
       "         'consume': 1,\n",
       "         'chasing': 1,\n",
       "         'prowess': 1,\n",
       "         'stop': 1,\n",
       "         'meal': 1,\n",
       "         'absolutely': 1,\n",
       "         'loved': 1,\n",
       "         'bring': 1,\n",
       "         'case': 1,\n",
       "         'check': 1,\n",
       "         'escaping': 1,\n",
       "         'travel': 1,\n",
       "         'mandatory': 1,\n",
       "         'find': 1,\n",
       "         'microbrewery': 1,\n",
       "         'flight': 1,\n",
       "         'sampling': 1,\n",
       "         'five': 1,\n",
       "         'half': 1,\n",
       "         'hour': 1,\n",
       "         'twin': 1,\n",
       "         'cities': 1,\n",
       "         'crackers': 1,\n",
       "         'brewery': 1,\n",
       "         'tour': 1,\n",
       "         'maybe': 1,\n",
       "         'occurs': 1,\n",
       "         'speakers': 1,\n",
       "         'happened': 1,\n",
       "         'odd': 1,\n",
       "         'neighborhood': 1,\n",
       "         'expect': 1,\n",
       "         'housing': 1,\n",
       "         'whatnot': 1,\n",
       "         'gargoyles': 1,\n",
       "         'dogs': 1,\n",
       "         'sitting': 1,\n",
       "         'inside': 1,\n",
       "         'shop': 1,\n",
       "         'cramped': 1,\n",
       "         'tasting': 1,\n",
       "         'phenomenal': 1,\n",
       "         'normal': 1,\n",
       "         'slash': 1,\n",
       "         'stops': 1,\n",
       "         'catching': 1,\n",
       "         'fire': 1,\n",
       "         'cross': 1,\n",
       "         'further': 1,\n",
       "         'north': 1,\n",
       "         'exponentially': 1,\n",
       "         'especially': 1,\n",
       "         'dirt': 1,\n",
       "         'married': 1,\n",
       "         'ST': 1,\n",
       "         'paul': 1,\n",
       "         'Northwest': 1,\n",
       "         'district': 1,\n",
       "         'crossed': 1,\n",
       "         'colors': 1,\n",
       "         'kept': 1,\n",
       "         'watering': 1,\n",
       "         'trees': 1,\n",
       "         'Except': 1,\n",
       "         'secret': 1,\n",
       "         'namely': 1,\n",
       "         'long': 1,\n",
       "         'Mississippi': 1,\n",
       "         'rebounds': 1,\n",
       "         'along': 1,\n",
       "         'drove': 1,\n",
       "         \"They've\": 1,\n",
       "         'northern': 1,\n",
       "         'town': 1,\n",
       "         'else': 1,\n",
       "         'training': 1,\n",
       "         'To': 1,\n",
       "         'train': 1,\n",
       "         'minutes': 1,\n",
       "         'barely': 1,\n",
       "         \"There's\": 1,\n",
       "         'ourselves': 1,\n",
       "         'fly': 1,\n",
       "         'drive': 1,\n",
       "         'iowan': 1,\n",
       "         'known': 1,\n",
       "         'self': 1,\n",
       "         'deprecating': 1,\n",
       "         'humor': 1,\n",
       "         'chill': 1,\n",
       "         'election': 1,\n",
       "         'season': 1,\n",
       "         'understood': 1,\n",
       "         \"Iowa's\": 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def make_candor_freq_counter(output_df):\n",
    "    return Counter(output_df['utterance'].tolist())\n",
    "make_candor_freq_counter(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candor_full_df(cliffhanger_df, output_df):\n",
    "    \"\"\"\n",
    "    Given transcribe_output.json and transcript_cliffhanger.csv\n",
    "    as loaded dataframes, return new cliffhanger_exploded df \n",
    "    mapping each word and their start/stop times to cliffhanger_df\n",
    "    \"\"\"\n",
    "    row_starts = []\n",
    "    row_stops = []\n",
    "    row_words = []\n",
    "    # row_surprisals = []\n",
    "    row_control_predictors = {}\n",
    "\n",
    "    for idx, row in cliffhanger_df.iterrows():\n",
    "        output_sub_df = output_df.query(\n",
    "            \"start >= @row.start & stop <= @row.stop & speaker == @row.speaker\"\n",
    "        )\n",
    "\n",
    "        row_starts.append(output_sub_df.start.tolist())\n",
    "        row_stops.append(output_sub_df.stop.tolist())\n",
    "\n",
    "        output_words = output_sub_df.utterance.tolist()\n",
    "\n",
    "        cliffhanger_words = row['utterance'].split(' ')#.strip?\n",
    "        row_words.append(cliffhanger_words) # or output_words, to remove punctuation\n",
    "\n",
    "        control_predictors = ControlPredictors(row['utterance'])\n",
    "        for predictor, values in control_predictors:\n",
    "            if predictor not in row_control_predictors:\n",
    "                row_control_predictors[predictor] = [values]\n",
    "            else:\n",
    "                row_control_predictors[predictor].append(values)\n",
    "    \n",
    "        # # Surprisals:\n",
    "        # inputs = tokenize_cliffhanger_turn(cliffhanger_words, tokenizer)\n",
    "        # surprisals = calculate_surprisal(inputs, model)\n",
    "        # surprisals_by_word = aggregate_surprisal_by_word(inputs, surprisals)\n",
    "\n",
    "        assert len(output_words) == len(cliffhanger_words), f\"output/cliffhanger transcript mismatch:\\n{output_words}\\n{cliffhanger_words}\\n\"\n",
    "        # assert len(cliffhanger_words) == len(surprisals_by_word), f\"cliffhanger_words/surprisals_by_word mismatch:\\n{cliffhanger_words}\\n{surprisals_by_word}\\n\"\n",
    "\n",
    "    cliffhanger_df_minimal = cliffhanger_df.loc[:, ['turn_id']]\n",
    "    cliffhanger_df_minimal[\"word\"] = cliffhanger_df[\"utterance\"].str.split(' ')\n",
    "    cliffhanger_df_minimal[\"word_start\"] = row_starts\n",
    "    cliffhanger_df_minimal[\"word_stop\"] = row_stops\n",
    "    # cliffhanger_df_minimal[\"surprisal\"] = row_surprisals\n",
    "    for predictor, values in row_control_predictors.items():\n",
    "        cliffhanger_df_minimal[predictor] = values\n",
    "\n",
    "\n",
    "    out = cliffhanger_df_minimal.explode([\"word\", \"word_start\", \"word_stop\",] + [predictor for predictor in row_control_predictors])# \"surprisal\"])\n",
    "    out[\"position_in_turn\"] = out.groupby(\"turn_id\").cumcount()\n",
    "    return out.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>word</th>\n",
       "      <th>word_start</th>\n",
       "      <th>word_stop</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_syllables</th>\n",
       "      <th>pos</th>\n",
       "      <th>stopword</th>\n",
       "      <th>mtw</th>\n",
       "      <th>sentence_id_in_turn</th>\n",
       "      <th>word_id_in_sentence</th>\n",
       "      <th>position_in_turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mhm.</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.66</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mhm.</td>\n",
       "      <td>10.14</td>\n",
       "      <td>10.95</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>Mhm</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Just,</td>\n",
       "      <td>12.74</td>\n",
       "      <td>14.36</td>\n",
       "      <td>Just</td>\n",
       "      <td>just</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mm.</td>\n",
       "      <td>17.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>mm</td>\n",
       "      <td>mm</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>And</td>\n",
       "      <td>18.74</td>\n",
       "      <td>19.06</td>\n",
       "      <td>And</td>\n",
       "      <td>and</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>322</td>\n",
       "      <td>good</td>\n",
       "      <td>2732.43</td>\n",
       "      <td>2732.56</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>322</td>\n",
       "      <td>night.</td>\n",
       "      <td>2732.56</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>night</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>323</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>2732.59</td>\n",
       "      <td>2732.79</td>\n",
       "      <td>Yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>323</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>2733.29</td>\n",
       "      <td>2734.09</td>\n",
       "      <td>Yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>324</td>\n",
       "      <td>But</td>\n",
       "      <td>2734.39</td>\n",
       "      <td>2734.66</td>\n",
       "      <td>But</td>\n",
       "      <td>but</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7721 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      turn_id    word word_start word_stop   text  lemma n_chars n_syllables  \\\n",
       "0           0    Mhm.       4.34      4.66    Mhm    Mhm       3           2   \n",
       "1           0    Mhm.      10.14     10.95    Mhm    Mhm       3           2   \n",
       "2           0   Just,      12.74     14.36   Just   just       4           1   \n",
       "3           0     mm.      17.74     17.95     mm     mm       2        None   \n",
       "4           0     And      18.74     19.06    And    and       3           1   \n",
       "...       ...     ...        ...       ...    ...    ...     ...         ...   \n",
       "7716      322    good    2732.43   2732.56   good   good       4           1   \n",
       "7717      322  night.    2732.56    2733.0  night  night       5           1   \n",
       "7718      323   Yeah.    2732.59   2732.79   Yeah   yeah       4           1   \n",
       "7719      323   Yeah.    2733.29   2734.09   Yeah   yeah       4           1   \n",
       "7720      324     But    2734.39   2734.66    But    but       3           1   \n",
       "\n",
       "        pos stopword    mtw sentence_id_in_turn word_id_in_sentence  \\\n",
       "0     PROPN    False  False                   0                   0   \n",
       "1     PROPN    False  False                   1                   0   \n",
       "2       ADV     True  False                   2                   0   \n",
       "3      INTJ    False  False                   2                   1   \n",
       "4     CCONJ     True  False                   3                   0   \n",
       "...     ...      ...    ...                 ...                 ...   \n",
       "7716    ADJ    False  False                   1                   2   \n",
       "7717   NOUN    False  False                   1                   3   \n",
       "7718   INTJ    False  False                   0                   0   \n",
       "7719   INTJ    False  False                   1                   0   \n",
       "7720  CCONJ     True  False                   0                   0   \n",
       "\n",
       "      position_in_turn  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    2  \n",
       "3                    3  \n",
       "4                    4  \n",
       "...                ...  \n",
       "7716                 5  \n",
       "7717                 6  \n",
       "7718                 0  \n",
       "7719                 1  \n",
       "7720                 0  \n",
       "\n",
       "[7721 rows x 14 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = candor_full_df(cliffhanger_df, output_df)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to prepare dataframes for surprisal evaluation \n",
    "(à la COCA's text_bigram, text_sentence, text_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>sentence_id_in_turn</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Just, mm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>And Uh huh, mm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, you too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "      <td>Have a good night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>But</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     turn_id  sentence_id_in_turn            sentence\n",
       "0          0                    0                Mhm.\n",
       "1          0                    1                Mhm.\n",
       "2          0                    2           Just, mm.\n",
       "3          0                    3     And Uh huh, mm.\n",
       "4          0                    4                Mhm.\n",
       "..       ...                  ...                 ...\n",
       "851      322                    0       Yes, you too.\n",
       "852      322                    1  Have a good night.\n",
       "853      323                    0               Yeah.\n",
       "854      323                    1               Yeah.\n",
       "855      324                    0                 But\n",
       "\n",
       "[856 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentence = full_df.groupby(['turn_id', 'sentence_id_in_turn']).agg({\n",
    "    'word': lambda words: ' '.join(words)\n",
    "}).reset_index()\n",
    "text_sentence.rename(columns={'word': 'sentence'}, inplace=True)\n",
    "text_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bigrams(words):\n",
    "    yield ('<s>' + ' ' + words[0])\n",
    "    if len(words) > 1:\n",
    "        for i in range(0, len(words)-1):\n",
    "            yield (words[i] + ' ' + words[i+1])\n",
    "    yield (words[-1] + ' ' + '</s>')\n",
    "\n",
    "def gen_trigrams(words):\n",
    "    if len(words) == 1:\n",
    "        yield (' '.join(['<s>', words[0], '</s>']))\n",
    "        return\n",
    "\n",
    "    yield (' '.join(['<s>', words[0], words[1]]))\n",
    "    if len(words) > 2:\n",
    "        for i in range(0, len(words)-2):\n",
    "            yield (' '.join([words[i], words[i+1], words[i+2]]))\n",
    "    yield (' '.join([words[-2], words[-1], '</s>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "all_bigrams = []\n",
    "all_trigrams = []\n",
    "\n",
    "# Iterate through each group of sentences\n",
    "for (turn_id, sentence_id), group in full_df.groupby(['turn_id', 'sentence_id_in_turn']):\n",
    "    words = list(group['word'])\n",
    "    all_sentences.append({\n",
    "        'turn_id': turn_id, \n",
    "        'sentence_id_in_turn': sentence_id,\n",
    "        'sentence': ' '.join(words)})\n",
    "\n",
    "    for bigram in gen_bigrams(words):\n",
    "        all_bigrams.append({\n",
    "        'turn_id': turn_id, \n",
    "        'bigram': bigram})\n",
    "\n",
    "    for trigram in gen_trigrams(words):\n",
    "        all_trigrams.append({\n",
    "        'turn_id': turn_id, \n",
    "        'trigram': trigram})\n",
    "\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "text_sentence = pd.DataFrame(all_sentences)\n",
    "text_bigram = pd.DataFrame(all_bigrams)\n",
    "text_trigram = pd.DataFrame(all_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>sentence_id_in_turn</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Just, mm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>And Uh huh, mm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, you too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "      <td>Have a good night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>But</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     turn_id  sentence_id_in_turn            sentence\n",
       "0          0                    0                Mhm.\n",
       "1          0                    1                Mhm.\n",
       "2          0                    2           Just, mm.\n",
       "3          0                    3     And Uh huh, mm.\n",
       "4          0                    4                Mhm.\n",
       "..       ...                  ...                 ...\n",
       "851      322                    0       Yes, you too.\n",
       "852      322                    1  Have a good night.\n",
       "853      323                    0               Yeah.\n",
       "854      323                    1               Yeah.\n",
       "855      324                    0                 But\n",
       "\n",
       "[856 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mhm. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Mhm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mhm. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Just,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>323</td>\n",
       "      <td>Yeah. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>323</td>\n",
       "      <td>&lt;s&gt; Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>323</td>\n",
       "      <td>Yeah. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>324</td>\n",
       "      <td>&lt;s&gt; But</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>324</td>\n",
       "      <td>But &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      turn_id      bigram\n",
       "0           0    <s> Mhm.\n",
       "1           0   Mhm. </s>\n",
       "2           0    <s> Mhm.\n",
       "3           0   Mhm. </s>\n",
       "4           0   <s> Just,\n",
       "...       ...         ...\n",
       "8572      323  Yeah. </s>\n",
       "8573      323   <s> Yeah.\n",
       "8574      323  Yeah. </s>\n",
       "8575      324     <s> But\n",
       "8576      324    But </s>\n",
       "\n",
       "[8577 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_id</th>\n",
       "      <th>trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Mhm. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Mhm. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; Just, mm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Just, mm. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;s&gt; And Uh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>322</td>\n",
       "      <td>a good night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>322</td>\n",
       "      <td>good night. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>323</td>\n",
       "      <td>&lt;s&gt; Yeah. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>323</td>\n",
       "      <td>&lt;s&gt; Yeah. &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>324</td>\n",
       "      <td>&lt;s&gt; But &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      turn_id           trigram\n",
       "0           0     <s> Mhm. </s>\n",
       "1           0     <s> Mhm. </s>\n",
       "2           0     <s> Just, mm.\n",
       "3           0    Just, mm. </s>\n",
       "4           0        <s> And Uh\n",
       "...       ...               ...\n",
       "7716      322     a good night.\n",
       "7717      322  good night. </s>\n",
       "7718      323    <s> Yeah. </s>\n",
       "7719      323    <s> Yeah. </s>\n",
       "7720      324      <s> But </s>\n",
       "\n",
       "[7721 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_trigram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
